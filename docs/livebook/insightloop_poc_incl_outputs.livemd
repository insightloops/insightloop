# InsightLoop - Proof of Concept

```elixir
Mix.install([
  {:req_llm, "~> 1.0"},
  {:nimble_csv, "~> 1.3"},
  {:kino_explorer, "~> 0.1.25"},
  {:kino_vega_lite, "~> 0.1.13"}
])

# Setup the CSV Parser module
NimbleCSV.define(CsvParser, separator: ",", escape: "\"")
```

## Introduction

This notebook demonstrates the **InsightLoop Context Engine** - a data pipeline that:

1. **Loads** feedback from multiple CSV sources
2. **Enriches** feedback by mapping it to product areas and features using AI
3. **Clusters** similar feedback into insights
4. **Prioritizes** insights based on volume, sentiment, and user value

The goal: Transform scattered customer feedback into **high-confidence, traceable insights**.

---

## Section 0: Config

Add the root directories and constants we will use later on

```elixir
# CSV directories

# base_directory = "/mnt/d/dev/insightloop"
base_directory = "D:/dev/insightloop"

# Product map
product_areas_path = Path.join(base_directory, "Product_Areas.csv")
features_path = Path.join(base_directory, "Features.csv")

# VOC paths
feature_feedback_path = Path.join(base_directory, "VOC_Feature_Feedback.csv")
churn_survey_path = Path.join(base_directory, "VOC_Churn_Survey.csv")
nps_feedback_path = Path.join(base_directory, "VOC_NPS_General_Feedback.csv")
problem_validation_path = Path.join(base_directory, "VOC_Problem_Validation.csv")
user_interviews_path = Path.join(base_directory, "VOC_User_Interviews.csv")

# Claude sonnet 4.5 thinking model
model = "amazon-bedrock:us.anthropic.claude-sonnet-4-5-20250929-v1:0"

:ok
```

<!-- livebook:{"output":true} -->

```
:ok
```

## Section 1: Load Context Data (Product Areas & Features)

First, we load the **product taxonomy** - this gives the AI context about what features and areas exist in the product.

```elixir
# Load Product Areas
product_areas_raw =
  product_areas_path
  |> File.read!()
  |> CsvParser.parse_string(skip_headers: false)

[_headers | product_areas_data] = product_areas_raw

product_areas =
  product_areas_data
  |> Enum.map(fn [id, name, description, themes] ->
    %{
      id: id,
      name: name,
      description: description,
      example_themes: themes
    }
  end)

# Load Features
features_raw =
  features_path
  |> File.read!()
  |> CsvParser.parse_string(skip_headers: false)

[_headers | features_data] = features_raw

features =
  features_data
  |> Enum.map(fn [id, name, product_area_id, description] ->
    %{
      id: id,
      name: name,
      product_area_id: product_area_id,
      description: description
    }
  end)

IO.puts("âœ… Loaded #{length(product_areas)} product areas")
IO.puts("âœ… Loaded #{length(features)} features")

{product_areas, features}
```

<!-- livebook:{"output":true} -->

```
âœ… Loaded 8 product areas
âœ… Loaded 14 features
```

<!-- livebook:{"output":true} -->

```
{[
   %{
     id: "PA001",
     name: "Store Setup & Onboarding",
     description: "Experience from signup to first product launch",
     example_themes: "Setup confusing, payment gateway issues, onboarding friction"
   },
   %{
     id: "PA002",
     name: "AI Tools",
     description: "AI-powered features for automation and content generation",
     example_themes: "AI tone, Arabic support, irrelevant results"
   },
   %{
     id: "PA003",
     name: "Store Management",
     description: "Managing orders, products, and analytics",
     example_themes: "Crashes during sales, dashboard clarity, performance"
   },
   %{
     id: "PA004",
     name: "Pricing & Plans",
     description: "Subscription, billing, and plan tiers",
     example_themes: "Too expensive, plan confusion, upgrade issues"
   },
   %{
     id: "PA005",
     name: "Integrations & APIs",
     description: "Connections to shipping, payments, CRM, and third-party apps",
     example_themes: "Missing integration, API errors, sync delay"
   },
   %{
     id: "PA006",
     name: "Customer Support",
     description: "Help center, chat, and ticket resolution",
     example_themes: "Slow response, great support, missing help content"
   },
   %{
     id: "PA007",
     name: "Localization",
     description: "Arabic UX, translation, and RTL support",
     example_themes: "Arabic translation, layout issues, tone mismatch"
   },
   %{
     id: "PA008",
     name: "Reporting & Insights",
     description: "Analytics and feedback visualization",
     example_themes: "Need better insights, dashboard, and tracking"
   }
 ],
 [
   %{
     id: "F001",
     name: "Setup Wizard",
     description: "Guided step-by-step onboarding for new merchants",
     product_area_id: "PA001"
   },
   %{
     id: "F002",
     name: "Payment Gateway Connector",
     description: "Connect store with major payment providers",
     product_area_id: "PA001"
   },
   %{
     id: "F003",
     name: "AI Product Description Generator",
     description: "Automatically generates creative product descriptions",
     product_area_id: "PA002"
   },
   %{
     id: "F004",
     name: "AI Tone Trainer",
     description: "Allows user to personalize AI-generated content tone",
     product_area_id: "PA002"
   },
   %{
     id: "F005",
     name: "Order Management Dashboard",
     description: "View, track, and manage orders efficiently",
     product_area_id: "PA003"
   },
   %{
     id: "F006",
     name: "Subscription Manager",
     description: "Handle plan upgrades, billing, and invoices",
     product_area_id: "PA004"
   },
   %{
     id: "F007",
     name: "Invoice Generator",
     description: "Automatically generates invoices for customers",
     product_area_id: "PA004"
   },
   %{
     id: "F008",
     name: "API Key Manager",
     description: "Manage and secure developer API credentials",
     product_area_id: "PA005"
   },
   %{
     id: "F009",
     name: "Support Chat",
     description: "Live customer support chat system",
     product_area_id: "PA006"
   },
   %{
     id: "F010",
     name: "Help Center Articles",
     description: "Knowledge base with searchable help content",
     product_area_id: "PA006"
   },
   %{
     id: "F011",
     name: "Arabic RTL Theme",
     description: "Storefront layout optimized for right-to-left languages",
     product_area_id: "PA007"
   },
   %{id: "F012", name: "Language Switcher", ...},
   ...
 ]}
```

## View Product Areas

```elixir
require Explorer.DataFrame, as: DF

product_areas_df =
  product_areas
  |> DF.new()

product_areas_df
```

<!-- livebook:{"output":true} -->

```text
#Explorer.DataFrame<
  Polars[8 x 4]
  description string ["Experience from signup to first product launch", "AI-powered features for automation and content generation", "Managing orders, products, and analytics", "Subscription, billing, and plan tiers", "Connections to shipping, payments, CRM, and third-party apps", ...]
  example_themes string ["Setup confusing, payment gateway issues, onboarding friction", "AI tone, Arabic support, irrelevant results", "Crashes during sales, dashboard clarity, performance", "Too expensive, plan confusion, upgrade issues", "Missing integration, API errors, sync delay", ...]
  id string ["PA001", "PA002", "PA003", "PA004", "PA005", ...]
  name string ["Store Setup & Onboarding", "AI Tools", "Store Management", "Pricing & Plans", "Integrations & APIs", ...]
>
```

## View Features

```elixir
features_df =
  features
  |> DF.new()

features_df
```

<!-- livebook:{"output":true} -->

```text
#Explorer.DataFrame<
  Polars[14 x 4]
  description string ["Guided step-by-step onboarding for new merchants", "Connect store with major payment providers", "Automatically generates creative product descriptions", "Allows user to personalize AI-generated content tone", "View, track, and manage orders efficiently", ...]
  id string ["F001", "F002", "F003", "F004", "F005", ...]
  name string ["Setup Wizard", "Payment Gateway Connector", "AI Product Description Generator", "AI Tone Trainer", "Order Management Dashboard", ...]
  product_area_id string ["PA001", "PA001", "PA002", "PA002", "PA003", ...]
>
```

---

## Section 2: Load All Feedback Data

We'll load all 5 VOC sources and normalize them into a unified structure.

```elixir
defmodule FeedbackLoader do
  def load_feature_feedback(path) do
    path
    |> File.read!()
    |> CsvParser.parse_string(skip_headers: false)
    |> then(fn [_headers | data] -> data end)
    |> Enum.map(fn [user_id, frequency, satisfaction, working, frustrating, improvement] ->
      %{
        id: user_id,
        source: "feature_feedback",
        text: "What's working: #{working}. What's frustrating: #{frustrating}. Suggested improvement: #{improvement}",
        metadata: %{
          frequency: frequency,
          satisfaction: String.to_integer(satisfaction),
          working: working,
          frustrating: frustrating,
          improvement: improvement
        }
      }
    end)
  end

  def load_churn_survey(path) do
    path
    |> File.read!()
    |> CsvParser.parse_string(skip_headers: false)
    |> then(fn [_headers | data] -> data end)
    |> Enum.map(fn [customer_id, plan_type, duration, primary_reason, open_feedback, suggested_improvement] ->
      %{
        id: customer_id,
        source: "churn_survey",
        text: "Reason for churn: #{primary_reason}. Feedback: #{open_feedback}. Suggestion: #{suggested_improvement}",
        metadata: %{
          plan_type: plan_type,
          duration_months: duration,
          primary_reason: primary_reason,
          open_feedback: open_feedback,
          suggested_improvement: suggested_improvement
        }
      }
    end)
  end

  def load_nps_feedback(path) do
    path
    |> File.read!()
    |> CsvParser.parse_string(skip_headers: false)
    |> then(fn [_headers | data] -> data end)
    |> Enum.map(fn [user_id, nps_score, comment] ->
      %{
        id: user_id,
        source: "nps_feedback",
        text: comment,
        metadata: %{
          nps_score: String.to_integer(nps_score),
          comment: comment
        }
      }
    end)
  end

  def load_problem_validation(path) do
    path
    |> File.read!()
    |> CsvParser.parse_string(skip_headers: false)
    |> then(fn [_headers | data] -> data end)
    |> Enum.map(fn [respondent_id, role, company_size, biggest_pain, current_solution, ideal_solution] ->
      %{
        id: respondent_id,
        source: "problem_validation",
        text: "Biggest pain: #{biggest_pain}. Current solution: #{current_solution}. Ideal solution: #{ideal_solution}",
        metadata: %{
          role: role,
          company_size: company_size,
          biggest_pain: biggest_pain,
          current_solution: current_solution,
          ideal_solution: ideal_solution
        }
      }
    end)
  end

  def load_user_interviews(path) do
    path
    |> File.read!()
    |> CsvParser.parse_string(skip_headers: false)
    |> then(fn [_headers | data] -> data end)
    |> Enum.map(fn [interview_id, topic, language, transcript] ->
      %{
        id: interview_id,
        source: "user_interviews",
        text: "Interview about #{topic}: #{transcript}",
        metadata: %{
          topic: topic,
          language: language,
          transcript: transcript
        }
      }
    end)
  end

  def load_all(paths) do
    feature_feedback = load_feature_feedback(paths.feature_feedback)
    churn_survey = load_churn_survey(paths.churn_survey)
    nps_feedback = load_nps_feedback(paths.nps_feedback)
    problem_validation = load_problem_validation(paths.problem_validation)
    user_interviews = load_user_interviews(paths.user_interviews)

    IO.puts("âœ… Loaded #{length(feature_feedback)} feature feedback items")
    IO.puts("âœ… Loaded #{length(churn_survey)} churn survey items")
    IO.puts("âœ… Loaded #{length(nps_feedback)} NPS feedback items")
    IO.puts("âœ… Loaded #{length(problem_validation)} problem validation items")
    IO.puts("âœ… Loaded #{length(user_interviews)} user interview items")

    all_feedback = feature_feedback ++ churn_survey ++ nps_feedback ++ problem_validation ++ user_interviews

    IO.puts("\nğŸ¯ Total feedback items: #{length(all_feedback)}")

    all_feedback
  end
end

# Load all feedback sources
feedback_paths = %{
  feature_feedback: feature_feedback_path,
  churn_survey: churn_survey_path,
  nps_feedback: nps_feedback_path,
  problem_validation: problem_validation_path,
  user_interviews: user_interviews_path
}

feedback_items = FeedbackLoader.load_all(feedback_paths)
```

<!-- livebook:{"output":true} -->

```
âœ… Loaded 100 feature feedback items
âœ… Loaded 100 churn survey items
âœ… Loaded 100 NPS feedback items
âœ… Loaded 80 problem validation items
âœ… Loaded 7 user interview items

ğŸ¯ Total feedback items: 387
```

<!-- livebook:{"output":true} -->

```
[
  %{
    id: "FX001",
    metadata: %{
      working: "Helps me generate creative ideas.",
      frequency: "Monthly",
      satisfaction: 2,
      frustrating: "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙƒØªØ¨ Ø¨ØµÙŠØºØ© Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹.",
      improvement: "Highlight it better inside dashboard."
    },
    text: "What's working: Helps me generate creative ideas.. What's frustrating: Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙƒØªØ¨ Ø¨ØµÙŠØºØ© Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹.. Suggested improvement: Highlight it better inside dashboard.",
    source: "feature_feedback"
  },
  %{
    id: "FX002",
    metadata: %{
      working: "UI is simple and clear.",
      frequency: "Rarely",
      satisfaction: 5,
      frustrating: "Results sound robotic.",
      improvement: "Let users train it on their tone."
    },
    text: "What's working: UI is simple and clear.. What's frustrating: Results sound robotic.. Suggested improvement: Let users train it on their tone.",
    source: "feature_feedback"
  },
  %{
    id: "FX003",
    metadata: %{
      working: "Saves me time writing product descriptions.",
      frequency: "Rarely",
      satisfaction: 3,
      frustrating: "Hard to find where to enable it.",
      improvement: "Add multilingual support."
    },
    text: "What's working: Saves me time writing product descriptions.. What's frustrating: Hard to find where to enable it.. Suggested improvement: Add multilingual support.",
    source: "feature_feedback"
  },
  %{
    id: "FX004",
    metadata: %{
      working: "Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø³Ù‡Ù„Ø© ÙˆØ³Ø±ÙŠØ¹Ø©.",
      frequency: "Rarely",
      satisfaction: 5,
      frustrating: "Doesnâ€™t support Arabic well.",
      improvement: "Add multilingual support."
    },
    text: "What's working: Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø³Ù‡Ù„Ø© ÙˆØ³Ø±ÙŠØ¹Ø©.. What's frustrating: Doesnâ€™t support Arabic well.. Suggested improvement: Add multilingual support.",
    source: "feature_feedback"
  },
  %{
    id: "FX005",
    metadata: %{
      working: "UI is simple and clear.",
      frequency: "Rarely",
      satisfaction: 1,
      frustrating: "Doesnâ€™t support Arabic well.",
      improvement: "Improve relevance of results."
    },
    text: "What's working: UI is simple and clear.. What's frustrating: Doesnâ€™t support Arabic well.. Suggested improvement: Improve relevance of results.",
    source: "feature_feedback"
  },
  %{
    id: "FX006",
    metadata: %{
      working: "UI is simple and clear.",
      frequency: "Rarely",
      satisfaction: 5,
      frustrating: "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙƒØªØ¨ Ø¨ØµÙŠØºØ© Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹.",
      improvement: "Add multilingual support."
    },
    text: "What's working: UI is simple and clear.. What's frustrating: Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙƒØªØ¨ Ø¨ØµÙŠØºØ© Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹.. Suggested improvement: Add multilingual support.",
    source: "feature_feedback"
  },
  %{
    id: "FX007",
    metadata: %{
      working: "Easy to use and fast.",
      frequency: "Rarely",
      satisfaction: 3,
      frustrating: "Hard to find where to enable it.",
      improvement: "Let users train it on their tone."
    },
    text: "What's working: Easy to use and fast.. What's frustrating: Hard to find where to enable it.. Suggested improvement: Let users train it on their tone.",
    source: "feature_feedback"
  },
  %{
    id: "FX008",
    metadata: %{
      working: "Easy to use and fast.",
      frequency: "Daily",
      satisfaction: 1,
      frustrating: "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙƒØªØ¨ Ø¨ØµÙŠØºØ© Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹.",
      improvement: "Add multilingual support."
    },
    text: "What's working: Easy to use and fast.. What's frustrating: Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙƒØªØ¨ Ø¨ØµÙŠØºØ© Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹.. Suggested improvement: Add multilingual support.",
    source: "feature_feedback"
  },
  %{
    id: "FX009",
    metadata: %{
      working: "Easy to use and fast.",
      frequency: "Monthly",
      satisfaction: 4,
      frustrating: "Doesnâ€™t support Arabic well.",
      improvement: "Improve relevance of results."
    },
    text: "What's working: Easy to use and fast.. What's frustrating: Doesnâ€™t support Arabic well.. Suggested improvement: Improve relevance of results.",
    source: "feature_feedback"
  },
  %{
    id: "FX010",
    metadata: %{
      working: "Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø³Ù‡Ù„Ø© ÙˆØ³Ø±ÙŠØ¹Ø©.",
      frequency: "Weekly",
      satisfaction: 5,
      frustrating: "Hard to find where to enable it.",
      improvement: "Let users train it on their tone."
    },
    text: "What's working: Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø³Ù‡Ù„Ø© ÙˆØ³Ø±ÙŠØ¹Ø©.. What's frustrating: Hard to find where to enable it.. Suggested improvement: Let users train it on their tone.",
    source: "feature_feedback"
  },
  ...
]
```

## View Feedback as DataFrame

```elixir
feedback_df =
  feedback_items
  |> Enum.map(fn item ->
    %{
      id: item.id,
      source: item.source,
      text_preview: String.slice(item.text, 0..100) <> "..."
    }
  end)
  |> DF.new()

feedback_df
```

<!-- livebook:{"output":true} -->

```text
#Explorer.DataFrame<
  Polars[387 x 3]
  id string ["FX001", "FX002", "FX003", "FX004", "FX005", ...]
  source string ["feature_feedback", "feature_feedback", "feature_feedback", "feature_feedback", "feature_feedback", ...]
  text_preview string ["What's working: Helps me generate creative ideas.. What's frustrating: Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙƒØªØ¨ Ø¨ØµÙŠØºØ© Ø±Ø³...", "What's working: UI is simple and clear.. What's frustrating: Results sound robotic.. Suggested improv...", "What's working: Saves me time writing product descriptions.. What's frustrating: Hard to find where t...", "What's working: Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø³Ù‡Ù„Ø© ÙˆØ³Ø±ÙŠØ¹Ø©.. What's frustrating: Doesnâ€™t support Arabic well.. Suggested imp...", "What's working: UI is simple and clear.. What's frustrating: Doesnâ€™t support Arabic well.. Suggested ...", ...]
>
```

## View Feedback by Source

```elixir
feedback_by_source =
  feedback_items
  |> Enum.group_by(& &1.source)
  |> Enum.map(fn {source, items} -> {source, length(items)} end)
  |> Enum.sort_by(fn {_source, count} -> count end, :desc)

IO.puts("ğŸ“Š Feedback Distribution by Source:\n")

feedback_by_source
|> Enum.each(fn {source, count} ->
  IO.puts("  #{source}: #{count} items")
end)

feedback_by_source
```

<!-- livebook:{"output":true} -->

```
ğŸ“Š Feedback Distribution by Source:

  churn_survey: 100 items
  feature_feedback: 100 items
  nps_feedback: 100 items
  problem_validation: 80 items
  user_interviews: 7 items
```

<!-- livebook:{"output":true} -->

```
[
  {"churn_survey", 100},
  {"feature_feedback", 100},
  {"nps_feedback", 100},
  {"problem_validation", 80},
  {"user_interviews", 7}
]
```

## Sample Feedback Items from Each Source

Let's look at one feedback item from each source:

```elixir
IO.puts("ğŸ“‹ Sample Feedback from Each Source:\n")

feedback_items
|> Enum.group_by(& &1.source)
|> Enum.each(fn {source, items} ->
  sample = Enum.at(items, 0)
  IO.puts("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
  IO.puts("Source: #{source}")
  IO.puts("ID: #{sample.id}")
  IO.puts("Text: #{String.slice(sample.text, 0..150)}...")
  IO.puts("Metadata keys: #{inspect(Map.keys(sample.metadata))}")
  IO.puts("")
end)

# Return a few samples for inspection
feedback_items
|> Enum.take(3)
```

<!-- livebook:{"output":true} -->

```
ğŸ“‹ Sample Feedback from Each Source:

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Source: churn_survey
ID: CH001
Text: Reason for churn: Poor support. Feedback: I switched to Shopify because it offers more integrations.. Suggestion: Offer better integrations....
Metadata keys: [:plan_type, :primary_reason, :open_feedback, :suggested_improvement, :duration_months]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Source: feature_feedback
ID: FX001
Text: What's working: Helps me generate creative ideas.. What's frustrating: Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙƒØªØ¨ Ø¨ØµÙŠØºØ© Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹.. Suggested improvement: Highlight it bett...
Metadata keys: [:working, :frequency, :satisfaction, :frustrating, :improvement]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Source: nps_feedback
ID: NPS001
Text: Crashes sometimes when I upload many products....
Metadata keys: [:comment, :nps_score]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Source: problem_validation
ID: PV001
Text: Biggest pain: Difficult to share insights across teams.. Current solution: Rely on team memory.. Ideal solution: AI system that clusters feedback autom...
Metadata keys: [:role, :company_size, :biggest_pain, :current_solution, :ideal_solution]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Source: user_interviews
ID: INT01
Text: Interview about Understanding onboarding pain points: I: Can you tell me about your experience with understanding onboarding pain points? P: Overall, n...
Metadata keys: [:language, :topic, :transcript]

```

<!-- livebook:{"output":true} -->

```
[
  %{
    id: "FX001",
    metadata: %{
      working: "Helps me generate creative ideas.",
      frequency: "Monthly",
      satisfaction: 2,
      frustrating: "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙƒØªØ¨ Ø¨ØµÙŠØºØ© Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹.",
      improvement: "Highlight it better inside dashboard."
    },
    text: "What's working: Helps me generate creative ideas.. What's frustrating: Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙƒØªØ¨ Ø¨ØµÙŠØºØ© Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹.. Suggested improvement: Highlight it better inside dashboard.",
    source: "feature_feedback"
  },
  %{
    id: "FX002",
    metadata: %{
      working: "UI is simple and clear.",
      frequency: "Rarely",
      satisfaction: 5,
      frustrating: "Results sound robotic.",
      improvement: "Let users train it on their tone."
    },
    text: "What's working: UI is simple and clear.. What's frustrating: Results sound robotic.. Suggested improvement: Let users train it on their tone.",
    source: "feature_feedback"
  },
  %{
    id: "FX003",
    metadata: %{
      working: "Saves me time writing product descriptions.",
      frequency: "Rarely",
      satisfaction: 3,
      frustrating: "Hard to find where to enable it.",
      improvement: "Add multilingual support."
    },
    text: "What's working: Saves me time writing product descriptions.. What's frustrating: Hard to find where to enable it.. Suggested improvement: Add multilingual support.",
    source: "feature_feedback"
  }
]
```

---

## Section 3: Configure AWS Bedrock

We'll use AWS Bedrock to call Claude Sonnet 4.5 for relationship extraction.

**Provide your AWS credentials below (or use environment variables):**

```elixir
# AWS Credential Inputs
aws_access_key_input = Kino.Input.password("AWS Access Key ID:")
aws_secret_key_input = Kino.Input.password("AWS Secret Access Key:")
aws_region_input = Kino.Input.text("AWS Region:", default: "us-east-1")

Kino.Layout.grid([aws_access_key_input, aws_secret_key_input, aws_region_input], columns: 1)
```

```elixir
# Read AWS credentials from inputs or environment variables
aws_access_key = Kino.Input.read(aws_access_key_input)
aws_secret_key = Kino.Input.read(aws_secret_key_input)
aws_region = Kino.Input.read(aws_region_input)

# ReqLLM.put_key(:aws_bedrock, aws_config)
# There is a bug with Bedrock provider in ReqLLM and have to use env vars
System.put_env("AWS_ACCESS_KEY_ID", aws_access_key)
System.put_env("AWS_SECRET_ACCESS_KEY", aws_secret_key)
System.put_env("AWS_REGION", aws_region)
```

<!-- livebook:{"output":true} -->

```
:ok
```

## Test Bedrock Connection

Let's verify the Bedrock connection works:

```elixir
test_result =
  ReqLLM.generate_text(
    model,
    "Respond with just the word 'SUCCESS' if you can read this message."
  )

case test_result do
  {:ok, response} ->
    IO.puts("âœ… Bedrock connection successful!")
    text = ReqLLM.Response.text(response)
    IO.puts("Response: #{text}")
    text

  {:error, error} ->
    IO.puts("âŒ Bedrock connection failed")
    error
end
```

<!-- livebook:{"output":true} -->

```
âœ… Bedrock connection successful!
Response: SUCCESS
```

<!-- livebook:{"output":true} -->

```
"SUCCESS"
```

## Create Context Formatting Helper

This function formats our product areas and features into a clear context string for the LLM:

```elixir
defmodule ContextFormatter do
  def format_product_areas(product_areas) do
    product_areas
    |> Enum.map(fn area ->
      """
      - #{area.id}: #{area.name}
        Description: #{area.description}
        Common themes: #{area.example_themes}
      """
    end)
    |> Enum.join("\n")
  end

  def format_features(features) do
    features
    |> Enum.map(fn feature ->
      "- #{feature.id}: #{feature.name} (#{feature.product_area_id}) - #{feature.description}"
    end)
    |> Enum.join("\n")
  end
end

# Test the formatter
IO.puts("ğŸ“¦ PRODUCT AREAS:")
IO.puts(ContextFormatter.format_product_areas(product_areas))
IO.puts("\nğŸ”§ FEATURES:")
IO.puts(ContextFormatter.format_features(features))
```

<!-- livebook:{"output":true} -->

```
ğŸ“¦ PRODUCT AREAS:
- PA001: Store Setup & Onboarding
  Description: Experience from signup to first product launch
  Common themes: Setup confusing, payment gateway issues, onboarding friction

- PA002: AI Tools
  Description: AI-powered features for automation and content generation
  Common themes: AI tone, Arabic support, irrelevant results

- PA003: Store Management
  Description: Managing orders, products, and analytics
  Common themes: Crashes during sales, dashboard clarity, performance

- PA004: Pricing & Plans
  Description: Subscription, billing, and plan tiers
  Common themes: Too expensive, plan confusion, upgrade issues

- PA005: Integrations & APIs
  Description: Connections to shipping, payments, CRM, and third-party apps
  Common themes: Missing integration, API errors, sync delay

- PA006: Customer Support
  Description: Help center, chat, and ticket resolution
  Common themes: Slow response, great support, missing help content

- PA007: Localization
  Description: Arabic UX, translation, and RTL support
  Common themes: Arabic translation, layout issues, tone mismatch

- PA008: Reporting & Insights
  Description: Analytics and feedback visualization
  Common themes: Need better insights, dashboard, and tracking


ğŸ”§ FEATURES:
- F001: Setup Wizard (PA001) - Guided step-by-step onboarding for new merchants
- F002: Payment Gateway Connector (PA001) - Connect store with major payment providers
- F003: AI Product Description Generator (PA002) - Automatically generates creative product descriptions
- F004: AI Tone Trainer (PA002) - Allows user to personalize AI-generated content tone
- F005: Order Management Dashboard (PA003) - View, track, and manage orders efficiently
- F006: Subscription Manager (PA004) - Handle plan upgrades, billing, and invoices
- F007: Invoice Generator (PA004) - Automatically generates invoices for customers
- F008: API Key Manager (PA005) - Manage and secure developer API credentials
- F009: Support Chat (PA006) - Live customer support chat system
- F010: Help Center Articles (PA006) - Knowledge base with searchable help content
- F011: Arabic RTL Theme (PA007) - Storefront layout optimized for right-to-left languages
- F012: Language Switcher (PA007) - Allows users to toggle between Arabic and English views
- F013: Performance Analytics (PA008) - Displays traffic and performance metrics
- F014: Feedback Dashboard (PA008) - Aggregates and visualizes customer feedback trends
```

<!-- livebook:{"output":true} -->

```
:ok
```

---

## Section 4: Agent 1 - Relationship Extraction

This agent analyzes a feedback item and identifies:

* Which product areas it relates to
* Which features it mentions
* The core theme/issue
* Sentiment and urgency

```elixir
defmodule RelationshipExtractor do
  @model "amazon-bedrock:us.anthropic.claude-sonnet-4-5-20250929-v1:0"

  # Schema for structured output
  @output_schema [
    product_areas: [type: {:list, :string}, required: true],
    features: [type: {:list, :string}, required: true],
    theme: [type: :string, required: true],
    sentiment: [type: :string, required: true],
    urgency: [type: :string, required: true]
  ]

  def build_prompt(feedback, product_areas, features) do
    areas_context = ContextFormatter.format_product_areas(product_areas)
    features_context = ContextFormatter.format_features(features)

    # Build metadata context from available fields
    metadata_lines = []

    metadata_lines = if Map.has_key?(feedback.metadata, :satisfaction) do
      ["Satisfaction: #{feedback.metadata.satisfaction}/5" | metadata_lines]
    else
      metadata_lines
    end

    metadata_lines = if Map.has_key?(feedback.metadata, :frequency) do
      ["Frequency of use: #{feedback.metadata.frequency}" | metadata_lines]
    else
      metadata_lines
    end

    metadata_lines = if Map.has_key?(feedback.metadata, :nps_score) do
      ["NPS Score: #{feedback.metadata.nps_score}/10" | metadata_lines]
    else
      metadata_lines
    end

    metadata_lines = if Map.has_key?(feedback.metadata, :plan_type) do
      ["Plan Type: #{feedback.metadata.plan_type}" | metadata_lines]
    else
      metadata_lines
    end

    metadata_context = if Enum.empty?(metadata_lines) do
      ""
    else
      Enum.reverse(metadata_lines) |> Enum.join("\n    ") |> then(&("\n    " <> &1))
    end

    """
    You are analyzing customer feedback for an e-commerce platform.

    Your task: Identify which product areas and features this feedback relates to.

    PRODUCT AREAS:
    #{areas_context}

    FEATURES:
    #{features_context}

    FEEDBACK TO ANALYZE:
    Source: #{feedback.source}#{metadata_context}

    Text: "#{feedback.text}"

    Analyze this feedback and identify:
    - product_areas: Array of Product Area IDs (e.g., ["PA002", "PA007"])
    - features: Array of Feature IDs that are mentioned or implied (e.g., ["F003", "F004"])
    - theme: One clear sentence describing the main point
    - sentiment: Based on the satisfaction score and text tone (positive|negative|neutral|mixed)
    - urgency: How critical this issue is (low|medium|high)
    """
  end

  def extract(feedback, product_areas, features) do
    prompt = build_prompt(feedback, product_areas, features)

    # Call Bedrock via ReqLLM with structured output
    case ReqLLM.generate_object(@model, prompt, @output_schema) do
      {:ok, response} ->
        # Extract the validated object
        object = ReqLLM.Response.object(response)
        # Add source feedback ID for traceability
        {:ok, Map.put(object, "feedback_id", feedback.id)}

      {:error, error} ->
        {:error, error}
    end
  end
end

IO.puts("âœ… Relationship Extractor module loaded")
IO.puts("ğŸ¤– Model: #{model}")
```

<!-- livebook:{"output":true} -->

```
âœ… Relationship Extractor module loaded
ğŸ¤– Model: amazon-bedrock:us.anthropic.claude-sonnet-4-5-20250929-v1:0
```

<!-- livebook:{"output":true} -->

```
:ok
```

## Test Agent 1 on a Single Feedback Item

Let's process one feedback item and see the results:

```elixir
# Pick any feedback item to test
test_feedback = Enum.at(feedback_items, 0)

IO.puts("ğŸ“‹ Testing with feedback: #{test_feedback.id}")
IO.puts("Source: #{test_feedback.source}")
IO.puts("Text: #{String.slice(test_feedback.text, 0..200)}...")
IO.puts("\nâ³ Processing with Agent 1...")

# Extract relationships
result = RelationshipExtractor.extract(test_feedback, product_areas, features)

case result do
  {:ok, data} ->
    IO.puts("\nâœ… RESULT:")
    data

  {:error, error} ->
    IO.puts("\nâŒ ERROR:")
    error
end
```

<!-- livebook:{"output":true} -->

```
ğŸ“‹ Testing with feedback: FX001
Source: feature_feedback
Text: What's working: Helps me generate creative ideas.. What's frustrating: Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙƒØªØ¨ Ø¨ØµÙŠØºØ© Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹.. Suggested improvement: Highlight it better inside dashboard....

â³ Processing with Agent 1...

âœ… RESULT:
```

<!-- livebook:{"output":true} -->

```
%{
  "features" => ["F003", "F004", "F014"],
  "feedback_id" => "FX001",
  "product_areas" => ["PA002", "PA007", "PA008"],
  "sentiment" => "mixed",
  "theme" => "User finds AI content generation helpful but frustrating due to overly formal Arabic tone and poor discoverability in the dashboard",
  "urgency" => "medium"
}
```

## Validate the Output

Let's check if the extracted information makes sense:

```elixir
case result do
  {:ok, data} ->
    IO.puts("ğŸ¯ Relationship Extraction Results\n")
    IO.puts("Feedback ID: #{data["feedback_id"]}")
    IO.puts("\nğŸ“¦ Product Areas:")

    data["product_areas"]
    |> Enum.each(fn area_id ->
      area = Enum.find(product_areas, fn a -> a.id == area_id end)

      if area do
        IO.puts("  âœ“ #{area_id}: #{area.name}")
      else
        IO.puts("  âœ— #{area_id}: (not found in taxonomy)")
      end
    end)

    IO.puts("\nğŸ”§ Features:")

    data["features"]
    |> Enum.each(fn feature_id ->
      feature = Enum.find(features, fn f -> f.id == feature_id end)

      if feature do
        IO.puts("  âœ“ #{feature_id}: #{feature.name}")
      else
        IO.puts("  âœ— #{feature_id}: (not found in taxonomy)")
      end
    end)

    IO.puts("\nğŸ’¡ Theme: #{data["theme"]}")
    IO.puts("ğŸ˜Š Sentiment: #{data["sentiment"]}")
    IO.puts("âš¡ Urgency: #{data["urgency"]}")

  {:error, _error} ->
    IO.puts("âŒ Cannot validate - extraction failed")
end
```

<!-- livebook:{"output":true} -->

```
ğŸ¯ Relationship Extraction Results

Feedback ID: FX001

ğŸ“¦ Product Areas:
  âœ“ PA002: AI Tools
  âœ“ PA007: Localization
  âœ“ PA008: Reporting & Insights

ğŸ”§ Features:
  âœ“ F003: AI Product Description Generator
  âœ“ F004: AI Tone Trainer
  âœ“ F014: Feedback Dashboard

ğŸ’¡ Theme: User finds AI content generation helpful but frustrating due to overly formal Arabic tone and poor discoverability in the dashboard
ğŸ˜Š Sentiment: mixed
âš¡ Urgency: medium
```

<!-- livebook:{"output":true} -->

```
:ok
```

---

## Section 5: Batch Processing Configuration

Configure how many feedback items to process:

```elixir
batch_size_input = Kino.Input.number("Batch Size (0 = process all):", default: 10)
delay_ms_input = Kino.Input.number("Delay between requests (ms):", default: 1000)

Kino.Layout.grid([batch_size_input, delay_ms_input], columns: 2)
```

## Process Batch with Progress Tracking

```elixir
batch_size = Kino.Input.read(batch_size_input)
delay_ms = Kino.Input.read(delay_ms_input)

# Determine how many items to process
items_to_process = if batch_size == 0 do
  IO.puts("ğŸ“Š Processing ALL #{length(feedback_items)} feedback items\n")
  feedback_items
else
  IO.puts("ğŸ“Š Processing #{batch_size} feedback items\n")
  Enum.take(feedback_items, batch_size)
end

total = length(items_to_process)
start_time = System.monotonic_time(:second)

enriched_feedback =
  items_to_process
  |> Enum.with_index(1)
  |> Enum.map(fn {feedback, index} ->
    # Calculate progress
    progress = Float.round(index / total * 100, 1)
    elapsed = System.monotonic_time(:second) - start_time
    avg_time_per_item = if index > 1, do: elapsed / (index - 1), else: 0
    remaining_items = total - index
    eta_seconds = round(remaining_items * avg_time_per_item)
    
    IO.puts("[#{index}/#{total}] (#{progress}%) Processing: #{feedback.id} (#{feedback.source}) - ETA: #{eta_seconds}s")

    result = case RelationshipExtractor.extract(feedback, product_areas, features) do
      {:ok, extraction} ->
        IO.puts("  âœ“ Extracted: #{String.slice(extraction["theme"], 0..60)}...")
        
        # Merge original feedback with extraction results
        Map.merge(feedback, %{
          extracted_product_areas: extraction["product_areas"],
          extracted_features: extraction["features"],
          extracted_theme: extraction["theme"],
          extracted_sentiment: extraction["sentiment"],
          extracted_urgency: extraction["urgency"],
          extraction_error: false
        })

      {:error, error} ->
        IO.puts("  âš ï¸  Error: #{inspect(error)}")

        Map.merge(feedback, %{
          extracted_product_areas: [],
          extracted_features: [],
          extracted_theme: "Error during extraction",
          extracted_sentiment: "unknown",
          extracted_urgency: "unknown",
          extraction_error: true
        })
    end

    # Delay to avoid rate limits (except for last item)
    if index < total do
      Process.sleep(delay_ms)
    end
    
    result
  end)

end_time = System.monotonic_time(:second)
total_time = end_time - start_time
avg_time = Float.round(total_time / total, 2)

IO.puts("\n" <> String.duplicate("â”", 50))
IO.puts("âœ… Batch processing complete!")
IO.puts("   Total items: #{total}")
IO.puts("   Time taken: #{total_time} seconds")
IO.puts("   Average per item: #{avg_time}s")
IO.puts("   Success rate: #{length(Enum.filter(enriched_feedback, &(!&1.extraction_error)))} / #{total}")
IO.puts(String.duplicate("â”", 50) <> "\n")

enriched_feedback
```

<!-- livebook:{"output":true} -->

```
ğŸ“Š Processing 10 feedback items

[1/10] (10.0%) Processing: FX001 (feature_feedback) - ETA: 0s
  âœ“ Extracted: User finds AI content generation helpful for ideas but is fru...
[2/10] (20.0%) Processing: FX002 (feature_feedback) - ETA: 56s
  âœ“ Extracted: User appreciates the simple UI but finds AI-generated content...
[3/10] (30.0%) Processing: FX003 (feature_feedback) - ETA: 39s
  âœ“ Extracted: AI product description generator is useful but difficult to l...
[4/10] (40.0%) Processing: FX004 (feature_feedback) - ETA: 30s
  âœ“ Extracted: User appreciates the easy and fast experience but needs bette...
[5/10] (50.0%) Processing: FX005 (feature_feedback) - ETA: 24s
  âœ“ Extracted: User appreciates simple UI but frustrated with poor Arabic la...
[6/10] (60.0%) Processing: FX006 (feature_feedback) - ETA: 18s
  âœ“ Extracted: User appreciates the simple UI but finds AI-generated content...
[7/10] (70.0%) Processing: FX007 (feature_feedback) - ETA: 14s
  âœ“ Extracted: User finds the AI tool fast and easy to use but struggles wit...
[8/10] (80.0%) Processing: FX008 (feature_feedback) - ETA: 9s
  âœ“ Extracted: AI-generated content uses overly formal tone in Arabic, needs...
[9/10] (90.0%) Processing: FX009 (feature_feedback) - ETA: 5s
  âœ“ Extracted: User appreciates the platform's ease of use and speed but fac...
[10/10] (100.0%) Processing: FX010 (feature_feedback) - ETA: 0s
  âœ“ Extracted: User appreciates the AI tool's ease of use but struggles with...

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Batch processing complete!
   Total items: 10
   Time taken: 43 seconds
   Average per item: 4.3s
   Success rate: 10 / 10
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

```

<!-- livebook:{"output":true} -->

```
[
  %{
    id: "FX001",
    metadata: %{
      working: "Helps me generate creative ideas.",
      frequency: "Monthly",
      satisfaction: 2,
      frustrating: "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙƒØªØ¨ Ø¨ØµÙŠØºØ© Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹.",
      improvement: "Highlight it better inside dashboard."
    },
    text: "What's working: Helps me generate creative ideas.. What's frustrating: Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙƒØªØ¨ Ø¨ØµÙŠØºØ© Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹.. Suggested improvement: Highlight it better inside dashboard.",
    source: "feature_feedback",
    extracted_product_areas: ["PA002", "PA007", "PA008"],
    extracted_features: ["F003", "F004", "F014"],
    extracted_theme: "User finds AI content generation helpful for ideas but is frustrated by overly formal Arabic tone and wants better visibility of the feature in the dashboard.",
    extracted_sentiment: "mixed",
    extracted_urgency: "medium",
    extraction_error: false
  },
  %{
    id: "FX002",
    metadata: %{
      working: "UI is simple and clear.",
      frequency: "Rarely",
      satisfaction: 5,
      frustrating: "Results sound robotic.",
      improvement: "Let users train it on their tone."
    },
    text: "What's working: UI is simple and clear.. What's frustrating: Results sound robotic.. Suggested improvement: Let users train it on their tone.",
    source: "feature_feedback",
    extracted_product_areas: ["PA002"],
    extracted_features: ["F003", "F004"],
    extracted_theme: "User appreciates the simple UI but finds AI-generated content sounds robotic and wants the ability to customize the tone",
    extracted_sentiment: "mixed",
    extracted_urgency: "medium",
    extraction_error: false
  },
  %{
    id: "FX003",
    metadata: %{
      working: "Saves me time writing product descriptions.",
      frequency: "Rarely",
      satisfaction: 3,
      frustrating: "Hard to find where to enable it.",
      improvement: "Add multilingual support."
    },
    text: "What's working: Saves me time writing product descriptions.. What's frustrating: Hard to find where to enable it.. Suggested improvement: Add multilingual support.",
    source: "feature_feedback",
    extracted_product_areas: ["PA002", "PA007"],
    extracted_features: ["F003", "F012"],
    extracted_theme: "AI product description generator is useful but difficult to locate, and needs multilingual support for broader applicability.",
    extracted_sentiment: "mixed",
    extracted_urgency: "medium",
    extraction_error: false
  },
  %{
    id: "FX004",
    metadata: %{
      working: "Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø³Ù‡Ù„Ø© ÙˆØ³Ø±ÙŠØ¹Ø©.",
      frequency: "Rarely",
      satisfaction: 5,
      frustrating: "Doesnâ€™t support Arabic well.",
      improvement: "Add multilingual support."
    },
    text: "What's working: Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø³Ù‡Ù„Ø© ÙˆØ³Ø±ÙŠØ¹Ø©.. What's frustrating: Doesnâ€™t support Arabic well.. Suggested improvement: Add multilingual support.",
    source: "feature_feedback",
    extracted_product_areas: ["PA007"],
    extracted_features: ["F012"],
    extracted_theme: "User appreciates the easy and fast experience but needs better Arabic language support and multilingual capabilities.",
    extracted_sentiment: "mixed",
    extracted_urgency: "medium",
    extraction_error: false
  },
  %{
    id: "FX005",
    metadata: %{
      working: "UI is simple and clear.",
      frequency: "Rarely",
      satisfaction: 1,
      frustrating: "Doesnâ€™t support Arabic well.",
      improvement: "Improve relevance of results."
    },
    text: "What's working: UI is simple and clear.. What's frustrating: Doesnâ€™t support Arabic well.. Suggested improvement: Improve relevance of results.",
    source: "feature_feedback",
    extracted_product_areas: ["PA007", "PA002"],
    extracted_features: ["F011", "F012", "F003"],
    extracted_theme: "User appreciates simple UI but frustrated with poor Arabic language support and irrelevant search/content results",
    extracted_sentiment: "mixed",
    extracted_urgency: "medium",
    extraction_error: false
  },
  ...
]
```

## Save/Load Enriched Feedback

Save processed results to avoid reprocessing:

```elixir
defmodule FeedbackCache do
  def save(enriched_feedback, base_directory, filename \\ "enriched_feedback.json") do
    path = Path.join(base_directory, filename)

    # Convert to JSON-friendly format
    data = %{
      processed_at: DateTime.utc_now() |> DateTime.to_iso8601(),
      count: length(enriched_feedback),
      items: enriched_feedback
    }

    json = JSON.encode_to_iodata!(data)
    File.write!(path, json)

    IO.puts("âœ… Saved #{length(enriched_feedback)} items to #{filename}")
    path
  end

  def load(base_directory, filename \\ "enriched_feedback.json") do
    path = Path.join(base_directory, filename)

    if File.exists?(path) do
      case File.read(path) do
        {:ok, content} ->
          case JSON.decode(content) do
            {:ok, data} ->
              # Convert string keys back to atoms for consistency
              items =
                Enum.map(data["items"], fn item ->
                  %{
                    id: item["id"],
                    source: item["source"],
                    text: item["text"],
                    metadata: item["metadata"],
                    extracted_product_areas: item["extracted_product_areas"],
                    extracted_features: item["extracted_features"],
                    extracted_theme: item["extracted_theme"],
                    extracted_sentiment: item["extracted_sentiment"],
                    extracted_urgency: item["extracted_urgency"],
                    extraction_error: item["extraction_error"]
                  }
                end)

              IO.puts("âœ… Loaded #{length(items)} items from #{filename}")
              IO.puts("   Processed at: #{data["processed_at"]}")
              {:ok, items}

            {:error, error} ->
              {:error, "Failed to parse JSON: #{inspect(error)}"}
          end

        {:error, error} ->
          {:error, "Failed to read file: #{inspect(error)}"}
      end
    else
      {:error, "File not found: #{path}"}
    end
  end
end

IO.puts("âœ… Feedback cache module loaded")
```

<!-- livebook:{"output":true} -->

```
âœ… Feedback cache module loaded
```

<!-- livebook:{"output":true} -->

```
:ok
```

## Save Current Batch (Optional)

```elixir
# Uncomment to save current enriched_feedback
# FeedbackCache.save(enriched_feedback, base_directory, "enriched_feedback_#{DateTime.utc_now() |> DateTime.to_unix()}.json")
```

<!-- livebook:{"output":true} -->

```
nil
```

## Load Previously Processed Data (Optional)

```elixir
# Uncomment to load previously saved data instead of reprocessing
enriched_feedback =
  case FeedbackCache.load(base_directory, "enriched_feedback_1763028905.json") do
    {:ok, loaded_feedback} ->
      IO.puts("Using loaded data with #{length(enriched_feedback)} items")
      loaded_feedback

    {:error, error} ->
      IO.puts("Could not load cache: #{error}")
      IO.puts("Using current enriched_feedback")
  end
```

<!-- livebook:{"output":true} -->

```
âœ… Loaded 387 items from enriched_feedback_1763028905.json
   Processed at: 2025-11-13T10:15:05.780000Z
Using loaded data with 10 items
```

<!-- livebook:{"output":true} -->

```
[
  %{
    id: "FX001",
    metadata: %{
      "frequency" => "Monthly",
      "frustrating" => "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙƒØªØ¨ Ø¨ØµÙŠØºØ© Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹.",
      "improvement" => "Highlight it better inside dashboard.",
      "satisfaction" => 2,
      "working" => "Helps me generate creative ideas."
    },
    text: "What's working: Helps me generate creative ideas.. What's frustrating: Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙƒØªØ¨ Ø¨ØµÙŠØºØ© Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹.. Suggested improvement: Highlight it better inside dashboard.",
    source: "feature_feedback",
    extracted_product_areas: ["PA002", "PA007", "PA008"],
    extracted_features: ["F003", "F004", "F013", "F014"],
    extracted_theme: "AI-generated content is helpful for creativity but uses overly formal Arabic tone, and the feature needs better visibility in the dashboard.",
    extracted_sentiment: "mixed",
    extracted_urgency: "medium",
    extraction_error: false
  },
  %{
    id: "FX002",
    metadata: %{
      "frequency" => "Rarely",
      "frustrating" => "Results sound robotic.",
      "improvement" => "Let users train it on their tone.",
      "satisfaction" => 5,
      "working" => "UI is simple and clear."
    },
    text: "What's working: UI is simple and clear.. What's frustrating: Results sound robotic.. Suggested improvement: Let users train it on their tone.",
    source: "feature_feedback",
    extracted_product_areas: ["PA002"],
    extracted_features: ["F003", "F004"],
    extracted_theme: "User appreciates the simple UI but finds AI-generated content sounds robotic and wants the ability to customize the AI tone to match their brand voice",
    extracted_sentiment: "mixed",
    extracted_urgency: "medium",
    extraction_error: false
  },
  %{
    id: "FX003",
    metadata: %{
      "frequency" => "Rarely",
      "frustrating" => "Hard to find where to enable it.",
      "improvement" => "Add multilingual support.",
      "satisfaction" => 3,
      "working" => "Saves me time writing product descriptions."
    },
    text: "What's working: Saves me time writing product descriptions.. What's frustrating: Hard to find where to enable it.. Suggested improvement: Add multilingual support.",
    source: "feature_feedback",
    extracted_product_areas: ["PA002", "PA007"],
    extracted_features: ["F003", "F012"],
    extracted_theme: "User values the AI product description tool for time savings but struggles with discoverability and needs multilingual support.",
    extracted_sentiment: "mixed",
    extracted_urgency: "medium",
    extraction_error: false
  },
  %{
    id: "FX004",
    metadata: %{
      "frequency" => "Rarely",
      "frustrating" => "Doesnâ€™t support Arabic well.",
      "improvement" => "Add multilingual support.",
      "satisfaction" => 5,
      "working" => "Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø³Ù‡Ù„Ø© ÙˆØ³Ø±ÙŠØ¹Ø©."
    },
    text: "What's working: Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø³Ù‡Ù„Ø© ÙˆØ³Ø±ÙŠØ¹Ø©.. What's frustrating: Doesnâ€™t support Arabic well.. Suggested improvement: Add multilingual support.",
    source: "feature_feedback",
    extracted_product_areas: ["PA007"],
    extracted_features: ["F011", "F012"],
    extracted_theme: "User appreciates the ease and speed of the experience but is frustrated by poor Arabic language support and requests multilingual capabilities.",
    extracted_sentiment: "mixed",
    extracted_urgency: "medium",
    extraction_error: false
  },
  %{
    id: "FX005",
    metadata: %{
      "frequency" => "Rarely",
      "frustrating" => "Doesnâ€™t support Arabic well.",
      "improvement" => "Improve relevance of results.",
      "satisfaction" => 1,
      "working" => "UI is simple and clear."
    },
    text: "What's working: UI is simple and clear.. What's frustrating: Doesnâ€™t support Arabic well.. Suggested improvement: Improve relevance of results.",
    source: "feature_feedback",
    extracted_product_areas: ["PA007", "PA002"],
    extracted_features: ["F011", "F012", "F003"],
    extracted_theme: "User appreciates the simple UI but experiences poor Arabic language support and irrelevant search/content results",
    extracted_sentiment: "mixed",
    ...
  },
  ...
]
```

## Parallel Processing (Optional - Faster for Large Batches)

For large batches, parallel processing can be much faster. Note: This may hit rate limits.

```elixir
defmodule ParallelProcessor do
  def process_batch(items, product_areas, features, opts \\ []) do
    max_concurrency = Keyword.get(opts, :max_concurrency, 5)
    timeout = Keyword.get(opts, :timeout, 30_000)
    
    total = length(items)
    start_time = System.monotonic_time(:second)
    
    IO.puts("âš¡ Processing #{total} items in parallel (max #{max_concurrency} concurrent)...\n")
    
    results =
      items
      |> Task.async_stream(
        fn feedback ->
          case RelationshipExtractor.extract(feedback, product_areas, features) do
            {:ok, extraction} ->
              {:ok, Map.merge(feedback, %{
                extracted_product_areas: extraction["product_areas"],
                extracted_features: extraction["features"],
                extracted_theme: extraction["theme"],
                extracted_sentiment: extraction["sentiment"],
                extracted_urgency: extraction["urgency"],
                extraction_error: false
              })}
            
            {:error, error} ->
              {:error, Map.merge(feedback, %{
                extracted_product_areas: [],
                extracted_features: [],
                extracted_theme: "Error during extraction",
                extracted_sentiment: "unknown",
                extracted_urgency: "unknown",
                extraction_error: true
              }), error}
          end
        end,
        max_concurrency: max_concurrency,
        timeout: timeout,
        ordered: true
      )
      |> Enum.with_index(1)
      |> Enum.map(fn {result, index} ->
        progress = Float.round(index / total * 100, 1)
        IO.write("\r[#{index}/#{total}] (#{progress}%) completed")
        
        case result do
          {:ok, {:ok, item}} -> item
          {:ok, {:error, item, _error}} -> item
          {:exit, reason} ->
            IO.puts("\n  âš ï¸  Task #{index} timed out or crashed: #{inspect(reason)}")
            Enum.at(items, index - 1)
            |> Map.merge(%{
              extracted_product_areas: [],
              extracted_features: [],
              extracted_theme: "Processing timeout",
              extracted_sentiment: "unknown",
              extracted_urgency: "unknown",
              extraction_error: true
            })
        end
      end)
    
    end_time = System.monotonic_time(:second)
    total_time = end_time - start_time
    avg_time = Float.round(total_time / total, 2)
    success_count = length(Enum.filter(results, &(!&1.extraction_error)))
    
    IO.puts("\n" <> String.duplicate("â”", 50))
    IO.puts("âš¡ Parallel processing complete!")
    IO.puts("   Total items: #{total}")
    IO.puts("   Time taken: #{total_time} seconds")
    IO.puts("   Average per item: #{avg_time}s")
    IO.puts("   Success rate: #{success_count} / #{total}")
    IO.puts("   Speedup: ~#{Float.round(max_concurrency * avg_time, 1)}x faster than sequential")
    IO.puts(String.duplicate("â”", 50) <> "\n")
    
    results
  end
end

IO.puts("âœ… Parallel processor module loaded")
```

<!-- livebook:{"output":true} -->

```
âœ… Parallel processor module loaded
```

<!-- livebook:{"output":true} -->

```
:ok
```

## Run Parallel Processing (Uncomment to Use)

```elixir
# Uncomment to use parallel processing instead of sequential
# WARNING: May hit rate limits with high concurrency
# 
# parallel_batch_size = 20
# items_for_parallel = Enum.take(feedback_items, parallel_batch_size)
# 
# enriched_feedback = ParallelProcessor.process_batch(
#   items_for_parallel,
#   product_areas,
#   features,
#   max_concurrency: 5,  # Adjust based on rate limits
#   timeout: 30_000       # 30 seconds per item
# )
```

<!-- livebook:{"output":true} -->

```
nil
```

---

## View Enriched Feedback

```elixir
enriched_df =
  enriched_feedback
  |> Enum.map(fn item ->
    %{
      id: item.id,
      source: item.source,
      sentiment: item.extracted_sentiment,
      urgency: item.extracted_urgency,
      theme: item.extracted_theme,
      product_areas: Enum.join(item.extracted_product_areas, ", "),
      features: Enum.join(item.extracted_features, ", "),
      error: item.extraction_error
    }
  end)
  |> DF.new()

enriched_df
```

<!-- livebook:{"output":true} -->

```text
#Explorer.DataFrame<
  Polars[387 x 8]
  error boolean [false, false, false, false, false, ...]
  features string ["F003, F004, F013, F014", "F003, F004", "F003, F012", "F011, F012", "F011, F012, F003", ...]
  id string ["FX001", "FX002", "FX003", "FX004", "FX005", ...]
  product_areas string ["PA002, PA007, PA008", "PA002", "PA002, PA007", "PA007", "PA007, PA002", ...]
  sentiment string ["mixed", "mixed", "mixed", "mixed", "mixed", ...]
  source string ["feature_feedback", "feature_feedback", "feature_feedback", "feature_feedback", "feature_feedback", ...]
  theme string ["AI-generated content is helpful for creativity but uses overly formal Arabic tone, and the feature needs better visibility in the dashboard.", "User appreciates the simple UI but finds AI-generated content sounds robotic and wants the ability to customize the AI tone to match their brand voice", "User values the AI product description tool for time savings but struggles with discoverability and needs multilingual support.", "User appreciates the ease and speed of the experience but is frustrated by poor Arabic language support and requests multilingual capabilities.", "User appreciates the simple UI but experiences poor Arabic language support and irrelevant search/content results", ...]
  urgency string ["medium", "medium", "medium", "medium", "medium", ...]
>
```

---

## Section 6: Agent 2 - Clustering

Now let's group similar feedback into thematic clusters to identify patterns across all sources.

```elixir
defmodule ThemeClusterer do
  @model "amazon-bedrock:us.anthropic.claude-sonnet-4-5-20250929-v1:0"

  # Schema for structured output - wrap clusters in an object for Bedrock compatibility
  @output_schema [
    clusters: [
      type: {:list, :map},
      required: true
    ]
  ]

  def build_clustering_prompt(feedback_themes) do
    themes_list = 
      feedback_themes
      |> Enum.with_index(1)
      |> Enum.map(fn {{id, theme, source}, idx} ->
        "#{idx}. [#{id}] (#{source}) - #{theme}"
      end)
      |> Enum.join("\n")

    """
    You are analyzing customer feedback themes to identify common patterns and group them into clusters.

    Your task: Group these feedback themes into meaningful clusters based on similarity.

    FEEDBACK THEMES:
    #{themes_list}

    Analyze these themes and create clusters of similar feedback.

    Output structure:
    - clusters: Array of cluster objects, each containing:
      - cluster_name: Brief descriptive name for this cluster
      - description: What this cluster represents
      - feedback_ids: Array of feedback IDs in this cluster

    Guidelines:
    - Create 5-10 clusters maximum
    - Each cluster should contain at least 2 feedback items
    - Cluster names should be clear and actionable (e.g., "Arabic localization issues", "Pricing concerns")
    - Group by topic/theme similarity, not just keywords
    - A feedback item should only appear in ONE cluster
    - If a theme doesn't fit any cluster, create a new cluster or put it in "Miscellaneous"
    """
  end

  def cluster_themes(enriched_feedback) do
    # Extract themes with IDs
    feedback_themes = 
      enriched_feedback
      |> Enum.map(fn item -> 
        {item.id, item.extracted_theme, item.source}
      end)

    prompt = build_clustering_prompt(feedback_themes)

    IO.puts("ğŸ”„ Sending #{length(feedback_themes)} themes to LLM for clustering...")

    case ReqLLM.generate_object(@model, prompt, @output_schema) do
      {:ok, response} ->
        # Extract the validated object
        object = ReqLLM.Response.object(response)
        {:ok, object["clusters"]}

      {:error, error} ->
        {:error, error}
    end
  end

  def enrich_clusters(clusters, enriched_feedback) do
    # Create lookup map
    feedback_map = Map.new(enriched_feedback, fn item -> {item.id, item} end)

    Enum.map(clusters, fn cluster ->
      # Get all feedback items in this cluster
      cluster_items = 
        cluster["feedback_ids"]
        |> Enum.map(fn id -> Map.get(feedback_map, id) end)
        |> Enum.reject(&is_nil/1)

      # Aggregate metadata
      product_areas = 
        cluster_items
        |> Enum.flat_map(& &1.extracted_product_areas)
        |> Enum.frequencies()
        |> Enum.sort_by(fn {_area, count} -> count end, :desc)
        |> Enum.take(3)
        |> Enum.map(fn {area, _count} -> area end)

      features = 
        cluster_items
        |> Enum.flat_map(& &1.extracted_features)
        |> Enum.frequencies()
        |> Enum.sort_by(fn {_feature, count} -> count end, :desc)
        |> Enum.take(5)
        |> Enum.map(fn {feature, _count} -> feature end)

      sentiment_dist = 
        cluster_items
        |> Enum.map(& &1.extracted_sentiment)
        |> Enum.frequencies()

      urgency_dist = 
        cluster_items
        |> Enum.map(& &1.extracted_urgency)
        |> Enum.frequencies()

      source_dist = 
        cluster_items
        |> Enum.map(& &1.source)
        |> Enum.frequencies()

      %{
        cluster_name: cluster["cluster_name"],
        description: cluster["description"],
        feedback_ids: cluster["feedback_ids"],
        feedback_count: length(cluster_items),
        top_product_areas: product_areas,
        top_features: features,
        sentiment_distribution: sentiment_dist,
        urgency_distribution: urgency_dist,
        source_distribution: source_dist,
        sample_themes: cluster_items |> Enum.take(3) |> Enum.map(& &1.extracted_theme)
      }
    end)
  end
end

IO.puts("âœ… Theme Clusterer module loaded")
```

<!-- livebook:{"output":true} -->

```
âœ… Theme Clusterer module loaded
```

<!-- livebook:{"output":true} -->

```
:ok
```

## Run Clustering on Enriched Feedback

```elixir
# Only cluster successfully processed feedback
successful_feedback = Enum.filter(enriched_feedback, fn f -> !f.extraction_error end)

IO.puts("ğŸ“Š Clustering #{length(successful_feedback)} feedback items...\n")

clustering_result = ThemeClusterer.cluster_themes(successful_feedback)

case clustering_result do
  {:ok, clusters} ->
    IO.puts("âœ… Created #{length(clusters)} clusters\n")
    clusters

  {:error, error} ->
    IO.puts("âŒ Clustering failed: #{inspect(error)}")
    []
end
```

<!-- livebook:{"output":true} -->

```
ğŸ“Š Clustering 387 feedback items...

ğŸ”„ Sending 387 themes to LLM for clustering...
âœ… Created 11 clusters

```

<!-- livebook:{"output":true} -->

```
[
  %{
    "cluster_name" => "AI Content Quality & Tone Customization",
    "description" => "Feedback about AI-generated content sounding robotic, overly formal (especially in Arabic), and lacking brand voice customization. Users request the ability to train and personalize AI tone to match their brand.",
    "feedback_ids" => ["FX001", "FX002", "FX007", "FX008", "FX010", "FX011", "FX013", "FX014",
     "FX015", "FX016", "FX018", "FX019", "FX020", "FX023", "FX024", "FX026", "FX029", "FX031",
     "FX036", "FX039", "FX040", "FX041", "FX045", "FX051", "FX052", "FX053", "FX054", "FX057",
     "FX058", "FX062", "FX063", "FX064", "FX066", "FX067", "FX069", "FX071", "FX072", "FX079",
     "FX081", "FX082", "FX084", "FX085", "FX086", "FX087", "FX088", "FX089", "FX093", "FX094",
     "FX096", "FX097", "FX099"]
  },
  %{
    "cluster_name" => "Arabic Language & Multilingual Support",
    "description" => "Users experiencing poor Arabic language support, requesting better multilingual capabilities, and needing improvements in Arabic dialect handling and localization across the platform.",
    "feedback_ids" => ["FX003", "FX004", "FX005", "FX006", "FX009", "FX017", "FX022", "FX025",
     "FX028", "FX029", "FX030", "FX034", "FX035", "FX037", "FX038", "FX043", "FX044", "FX046",
     "FX047", "FX055", "FX056", "FX059", "FX061", "FX068", "FX073", "FX074", "FX080", "FX083",
     "FX090", "FX091", "FX092", "FX095", "NPS022", "NPS026", "NPS029", "NPS035", "NPS038", "NPS039",
     "NPS040", "NPS043", "NPS058", ...]
  },
  ...
]
```

## Enrich Clusters with Metadata

```elixir
enriched_clusters =
  case clustering_result do
    {:ok, raw_clusters} ->
      enriched_clusters = ThemeClusterer.enrich_clusters(raw_clusters, successful_feedback)

      IO.puts("ğŸ¯ Enriched Clusters:\n")

      enriched_clusters
      |> Enum.with_index(1)
      |> Enum.each(fn {cluster, idx} ->
        IO.puts("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        IO.puts("#{idx}. #{cluster.cluster_name}")
        IO.puts("   Description: #{cluster.description}")
        IO.puts("   Feedback count: #{cluster.feedback_count}")
        IO.puts("   Top product areas: #{Enum.join(cluster.top_product_areas, ", ")}")
        IO.puts("   Top features: #{Enum.join(cluster.top_features, ", ")}")
        IO.puts("   Sentiment: #{inspect(cluster.sentiment_distribution)}")
        IO.puts("   Urgency: #{inspect(cluster.urgency_distribution)}")
        IO.puts("   Sources: #{inspect(cluster.source_distribution)}")
        IO.puts("")
      end)

      enriched_clusters

    {:error, _error} ->
      IO.puts("âš ï¸  Cannot enrich clusters - clustering failed")
      []
  end
```

<!-- livebook:{"output":true} -->

```
ğŸ¯ Enriched Clusters:

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. AI Content Quality & Tone Customization
   Description: Feedback about AI-generated content sounding robotic, overly formal (especially in Arabic), and lacking brand voice customization. Users request the ability to train and personalize AI tone to match their brand.
   Feedback count: 51
   Top product areas: PA002, PA007, PA008
   Top features: F003, F004, F014, F012, F001
   Sentiment: %{"mixed" => 51}
   Urgency: %{"high" => 2, "medium" => 49}
   Sources: %{"feature_feedback" => 51}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
2. Arabic Language & Multilingual Support
   Description: Users experiencing poor Arabic language support, requesting better multilingual capabilities, and needing improvements in Arabic dialect handling and localization across the platform.
   Feedback count: 53
   Top product areas: PA007, PA002, PA001
   Top features: F003, F012, F004, F011, F001
   Sentiment: %{"mixed" => 47, "negative" => 2, "neutral" => 2, "positive" => 2}
   Urgency: %{"high" => 3, "low" => 3, "medium" => 47}
   Sources: %{"feature_feedback" => 32, "nps_feedback" => 18, "user_interviews" => 3}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
3. Feature Discoverability & Dashboard Visibility
   Description: Users struggling to find features and settings in the dashboard, requesting better visibility, clearer UI placement, and improved discoverability of AI and other tools.
   Feedback count: 29
   Top product areas: PA002, PA007, PA008
   Top features: F003, F004, F014, F012, F005
   Sentiment: %{"mixed" => 29}
   Urgency: %{"low" => 2, "medium" => 27}
   Sources: %{"feature_feedback" => 29}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
4. AI Suggestion Relevance & Accuracy
   Description: Feedback about AI-generated suggestions and content being irrelevant, inaccurate, or not matching user needs despite the tool being easy to use.
   Feedback count: 42
   Top product areas: PA002, PA007, PA008
   Top features: F003, F004, F012, F011, F013
   Sentiment: %{"mixed" => 42}
   Urgency: %{"low" => 2, "medium" => 40}
   Sources: %{"feature_feedback" => 42}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
5. Pricing Concerns & Value Perception
   Description: Customers churning or expressing dissatisfaction due to high pricing, lack of affordable plans for small/seasonal businesses, poor value perception, and unexpected price increases.
   Feedback count: 59
   Top product areas: PA004, PA006, PA001
   Top features: F006, F009, F001, F002, F010
   Sentiment: %{"mixed" => 19, "negative" => 39, "neutral" => 1}
   Urgency: %{"high" => 39, "low" => 2, "medium" => 18}
   Sources: %{"churn_survey" => 43, "nps_feedback" => 15, "user_interviews" => 1}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
6. Support Response Time & Quality
   Description: Customers experiencing slow support response times, poor support quality, and requesting faster, more helpful support services despite often friendly interactions.
   Feedback count: 74
   Top product areas: PA006, PA001, PA004
   Top features: F009, F001, F010, F006, F002
   Sentiment: %{"mixed" => 31, "negative" => 19, "positive" => 24}
   Urgency: %{"high" => 44, "low" => 25, "medium" => 5}
   Sources: %{"churn_survey" => 44, "nps_feedback" => 24, "user_interviews" => 6}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
7. Onboarding, Setup & Payment Gateway Integration
   Description: Users struggling with confusing setup processes, difficult onboarding experiences, payment gateway connection issues, and need for better tutorials and localized help documentation.
   Feedback count: 44
   Top product areas: PA001, PA006, PA007
   Top features: F001, F002, F009, F010, F006
   Sentiment: %{"mixed" => 11, "negative" => 33}
   Urgency: %{"high" => 37, "medium" => 7}
   Sources: %{"churn_survey" => 38, "user_interviews" => 6}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
8. Platform Performance & Stability
   Description: Issues with platform performance during high-traffic periods (sales/promotions), system crashes during bulk uploads, uptime concerns, and slow system performance.
   Feedback count: 31
   Top product areas: PA003, PA007, PA004
   Top features: F005, F009, F001, F006, F010
   Sentiment: %{"mixed" => 6, "negative" => 25}
   Urgency: %{"high" => 27, "medium" => 4}
   Sources: %{"churn_survey" => 15, "nps_feedback" => 15, "user_interviews" => 1}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
9. Third-Party Integrations & Feature Gaps
   Description: Customers churning due to insufficient third-party integrations compared to competitors, lack of features suitable for small stores, and seasonal business needs not being met.
   Feedback count: 24
   Top product areas: PA005, PA004, PA006
   Top features: F009, F006, F010, F001, F002
   Sentiment: %{"mixed" => 11, "negative" => 13}
   Urgency: %{"high" => 19, "low" => 1, "medium" => 4}
   Sources: %{"churn_survey" => 23, "user_interviews" => 1}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
10. Centralized Feedback Management & AI Clustering
   Description: Need for centralized feedback repository, AI-powered automatic feedback clustering and analysis, better visualization of recurring pain points, and cross-team collaboration capabilities to replace manual tracking methods.
   Feedback count: 80
   Top product areas: PA008, PA002, PA005
   Top features: F014, F003, F013
   Sentiment: %{"negative" => 78, "neutral" => 2}
   Urgency: %{"high" => 56, "medium" => 24}
   Sources: %{"problem_validation" => 80}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
11. Positive Feedback: Platform Improvements & AI Productivity
   Description: Positive feedback about improved user experience after recent updates, high satisfaction with AI assistant's time-saving capabilities, and appreciation for platform improvements.
   Feedback count: 27
   Top product areas: PA003, PA002, PA007
   Top features: F003, F004, F011, F012, F001
   Sentiment: %{"mixed" => 6, "positive" => 21}
   Urgency: %{"low" => 25, "medium" => 2}
   Sources: %{"nps_feedback" => 27}

```

<!-- livebook:{"output":true} -->

```
[
  %{
    description: "Feedback about AI-generated content sounding robotic, overly formal (especially in Arabic), and lacking brand voice customization. Users request the ability to train and personalize AI tone to match their brand.",
    cluster_name: "AI Content Quality & Tone Customization",
    feedback_ids: ["FX001", "FX002", "FX007", "FX008", "FX010", "FX011", "FX013", "FX014", "FX015",
     "FX016", "FX018", "FX019", "FX020", "FX023", "FX024", "FX026", "FX029", "FX031", "FX036",
     "FX039", "FX040", "FX041", "FX045", "FX051", "FX052", "FX053", "FX054", "FX057", "FX058",
     "FX062", "FX063", "FX064", "FX066", "FX067", "FX069", "FX071", "FX072", "FX079", "FX081",
     "FX082", "FX084", "FX085", "FX086", "FX087", "FX088", "FX089", "FX093", "FX094", "FX096",
     "FX097", "FX099"],
    feedback_count: 51,
    top_product_areas: ["PA002", "PA007", "PA008"],
    top_features: ["F003", "F004", "F014", "F012", "F001"],
    sentiment_distribution: %{"mixed" => 51},
    urgency_distribution: %{"high" => 2, "medium" => 49},
    source_distribution: %{"feature_feedback" => 51},
    sample_themes: ["AI-generated content is helpful for creativity but uses overly formal Arabic tone, and the feature needs better visibility in the dashboard.",
     "User appreciates the simple UI but finds AI-generated content sounds robotic and wants the ability to customize the AI tone to match their brand voice",
     "User finds the AI tool fast and easy to use but struggles with discoverability and wants the ability to customize AI tone to match their brand voice."]
  },
  %{
    description: "Users experiencing poor Arabic language support, requesting better multilingual capabilities, and needing improvements in Arabic dialect handling and localization across the platform.",
    cluster_name: "Arabic Language & Multilingual Support",
    feedback_ids: ["FX003", "FX004", "FX005", "FX006", "FX009", "FX017", "FX022", "FX025", "FX028",
     "FX029", "FX030", "FX034", "FX035", "FX037", "FX038", "FX043", "FX044", "FX046", "FX047", ...],
    ...
  },
  ...
]
```

## View Clusters as DataFrame

```elixir
case clustering_result do
  {:ok, _clusters} ->
    clusters_df =
      enriched_clusters
      |> Enum.map(fn cluster ->
        %{
          cluster_name: cluster.cluster_name,
          feedback_count: cluster.feedback_count,
          product_areas: Enum.join(cluster.top_product_areas, ", "),
          features: Enum.join(cluster.top_features, ", "),
          dominant_sentiment: cluster.sentiment_distribution |> Enum.max_by(fn {_k, v} -> v end) |> elem(0),
          dominant_urgency: cluster.urgency_distribution |> Enum.max_by(fn {_k, v} -> v end) |> elem(0),
          sources: Map.keys(cluster.source_distribution) |> length()
        }
      end)
      |> DF.new()
    
    clusters_df

  {:error, _error} ->
    IO.puts("âš ï¸  No clusters to display")
    nil
end
```

<!-- livebook:{"output":true} -->

```text
#Explorer.DataFrame<
  Polars[11 x 7]
  cluster_name string ["AI Content Quality & Tone Customization", "Arabic Language & Multilingual Support", "Feature Discoverability & Dashboard Visibility", "AI Suggestion Relevance & Accuracy", "Pricing Concerns & Value Perception", ...]
  dominant_sentiment string ["mixed", "mixed", "mixed", "mixed", "negative", ...]
  dominant_urgency string ["medium", "medium", "medium", "medium", "high", ...]
  features string ["F003, F004, F014, F012, F001", "F003, F012, F004, F011, F001", "F003, F004, F014, F012, F005", "F003, F004, F012, F011, F013", "F006, F009, F001, F002, F010", ...]
  feedback_count s64 [51, 53, 29, 42, 59, ...]
  product_areas string ["PA002, PA007, PA008", "PA007, PA002, PA001", "PA002, PA007, PA008", "PA002, PA007, PA008", "PA004, PA006, PA001", ...]
  sources s64 [1, 3, 1, 1, 3, ...]
>
```

---

## Section 7: Agent 3 - Insight Generation

Now let's generate clear, actionable insights from our clusters with supporting evidence.

```elixir
defmodule InsightGenerator do
  @model "amazon-bedrock:us.anthropic.claude-sonnet-4-5-20250929-v1:0"

  # Schema for structured insight output
  @output_schema [
    insight_title: [type: :string, required: true],
    insight_summary: [type: :string, required: true],
    impact: [type: :string, required: true],
    affected_users: [type: :string, required: true],
    recommended_action: [type: :string, required: true],
    confidence_score: [type: :float, required: true],
    priority: [type: :string, required: true]
  ]

  def build_insight_prompt(cluster, enriched_feedback, product_areas, features) do
    # Get feedback items for this cluster
    feedback_map = Map.new(enriched_feedback, fn item -> {item.id, item} end)
    
    cluster_items = 
      cluster.feedback_ids
      |> Enum.map(fn id -> Map.get(feedback_map, id) end)
      |> Enum.reject(&is_nil/1)
    
    # Get sample quotes from cluster
    sample_quotes = 
      cluster_items
      |> Enum.take(5)
      |> Enum.map(fn item ->
        text = String.slice(item.text, 0..150)
        "- [#{item.id}] (#{item.source}): \"#{text}...\""
      end)
      |> Enum.join("\n")
    
    # Get product area names
    area_names = 
      cluster.top_product_areas
      |> Enum.map(fn area_id ->
        area = Enum.find(product_areas, fn a -> a.id == area_id end)
        if area, do: "#{area_id}: #{area.name}", else: area_id
      end)
      |> Enum.join(", ")
    
    # Get feature names
    feature_names = 
      cluster.top_features
      |> Enum.map(fn feature_id ->
        feature = Enum.find(features, fn f -> f.id == feature_id end)
        if feature, do: "#{feature_id}: #{feature.name}", else: feature_id
      end)
      |> Enum.join(", ")

    """
    You are a product insights analyst creating actionable insights from customer feedback.

    CLUSTER INFORMATION:
    Cluster Name: #{cluster.cluster_name}
    Description: #{cluster.description}
    Feedback Count: #{cluster.feedback_count} items
    
    AFFECTED AREAS:
    Product Areas: #{area_names}
    Features: #{feature_names}
    
    SENTIMENT BREAKDOWN:
    #{inspect(cluster.sentiment_distribution)}
    
    URGENCY BREAKDOWN:
    #{inspect(cluster.urgency_distribution)}
    
    SOURCE BREAKDOWN:
    #{inspect(cluster.source_distribution)}
    
    SAMPLE FEEDBACK:
    #{sample_quotes}

    Generate a clear, actionable insight based on this cluster.

    Guidelines:
    - insight_title: Clear, concise title (e.g., "Arabic Localization Gaps Causing Customer Frustration")
    - insight_summary: 2-3 sentences explaining the issue, its scope, and impact
    - impact: What's the business impact? (e.g., "Causing churn in MENA region", "Blocking Pro tier adoption")
    - affected_users: Who is affected? (e.g., "Arabic-speaking merchants, primarily in UAE and Saudi Arabia")
    - recommended_action: Specific, actionable next step (e.g., "Implement RTL layout support and hire Arabic UX writer")
    - confidence_score: Float between 0.0-1.0 based on feedback volume, consistency, and source diversity (more sources = higher confidence)
    - priority: "critical" (high urgency + negative sentiment + high volume), "high" (2 of 3), "medium" (1 of 3), "low" (nice to have)

    Consider:
    - Volume: #{cluster.feedback_count} mentions
    - Source diversity: #{map_size(cluster.source_distribution)} different sources
    - Sentiment: Is it mostly negative? That increases priority
    - Urgency: Are customers saying it's urgent? That increases priority
    """
  end

  def generate_insight(cluster, enriched_feedback, product_areas, features) do
    prompt = build_insight_prompt(cluster, enriched_feedback, product_areas, features)

    case ReqLLM.generate_object(@model, prompt, @output_schema) do
      {:ok, response} ->
        insight = ReqLLM.Response.object(response)
        
        # Add cluster metadata
        enriched_insight = Map.merge(insight, %{
          "cluster_id" => cluster.cluster_name,
          "feedback_count" => cluster.feedback_count,
          "feedback_ids" => cluster.feedback_ids,
          "product_areas" => cluster.top_product_areas,
          "features" => cluster.top_features,
          "sentiment_distribution" => cluster.sentiment_distribution,
          "urgency_distribution" => cluster.urgency_distribution,
          "source_distribution" => cluster.source_distribution
        })
        
        {:ok, enriched_insight}

      {:error, error} ->
        {:error, error}
    end
  end

  def generate_all_insights(clusters, enriched_feedback, product_areas, features) do
    total = length(clusters)
    IO.puts("ğŸ”„ Generating insights for #{total} clusters...\n")

    clusters
    |> Enum.with_index(1)
    |> Enum.map(fn {cluster, index} ->
      IO.puts("[#{index}/#{total}] Generating insight for: #{cluster.cluster_name}")

      case generate_insight(cluster, enriched_feedback, product_areas, features) do
        {:ok, insight} ->
          IO.puts("  âœ“ #{insight["insight_title"]}")
          {:ok, insight}

        {:error, error} ->
          IO.puts("  âš ï¸  Error: #{inspect(error)}")
          {:error, cluster.cluster_name, error}
      end
      |> tap(fn _ -> Process.sleep(1000) end)
    end)
  end
end

IO.puts("âœ… Insight Generator module loaded")
```

<!-- livebook:{"output":true} -->

```
âœ… Insight Generator module loaded
```

<!-- livebook:{"output":true} -->

```
:ok
```

## Generate Insights from Clusters

```elixir
insights =
  case clustering_result do
    {:ok, _clusters} ->
      IO.puts("ğŸ“Š Generating insights from #{length(enriched_clusters)} clusters...\n")

      insight_results =
        InsightGenerator.generate_all_insights(
          enriched_clusters,
          successful_feedback,
          product_areas,
          features
        )

      # Extract successful insights
      insights =
        insight_results
        |> Enum.filter(fn result ->
          case result do
            {:ok, _} -> true
            _ -> false
          end
        end)
        |> Enum.map(fn {:ok, insight} -> insight end)

      IO.puts("\nâœ… Generated #{length(insights)} insights")

      insights

    {:error, _error} ->
      IO.puts("âš ï¸  Cannot generate insights - clustering failed")
      []
  end
```

<!-- livebook:{"output":true} -->

```
ğŸ“Š Generating insights from 11 clusters...

ğŸ”„ Generating insights for 11 clusters...

[1/11] Generating insight for: AI Content Quality & Tone Customization
  âœ“ AI-Generated Content Lacks Brand Voice Customization and Sounds Overly Formal
[2/11] Generating insight for: Arabic Language & Multilingual Support
  âœ“ Arabic Language Support Gaps Hindering MENA Market Expansion
[3/11] Generating insight for: Feature Discoverability & Dashboard Visibility
  âœ“ Poor Feature Discoverability Blocking AI Tool Adoption
[4/11] Generating insight for: AI Suggestion Relevance & Accuracy
  âœ“ AI Suggestion Quality Issues Despite Positive UX Feedback
[5/11] Generating insight for: Pricing Concerns & Value Perception
  âœ“ High Pricing Driving Significant Churn Among Small and Trial-Converting Merchants
[6/11] Generating insight for: Support Response Time & Quality
  âœ“ Support Response Time Issues Driving Significant Customer Churn
[7/11] Generating insight for: Onboarding, Setup & Payment Gateway Integration
  âœ“ Critical Onboarding and Payment Setup Friction Driving High Churn
[8/11] Generating insight for: Platform Performance & Stability
  âœ“ Platform Performance Degradation During High-Traffic Events Driving Customer Churn
[9/11] Generating insight for: Third-Party Integrations & Feature Gaps
  âœ“ Integration Gaps and Pricing Inflexibility Driving Customer Churn
[10/11] Generating insight for: Centralized Feedback Management & AI Clustering
  âœ“ Lack of Centralized Feedback Management System Causing Cross-Team Inefficiencies
[11/11] Generating insight for: Positive Feedback: Platform Improvements & AI Productivity
  âœ“ AI Tools & Platform Updates Driving High User Satisfaction

âœ… Generated 11 insights
```

<!-- livebook:{"output":true} -->

```
[
  %{
    "affected_users" => "Merchants using AI content generation features across multiple markets, with significant impact on Arabic-speaking users in MENA region who find the formal tone culturally misaligned with their brand voice",
    "cluster_id" => "AI Content Quality & Tone Customization",
    "confidence_score" => 0.82,
    "features" => ["F003", "F004", "F014", "F012", "F001"],
    "feedback_count" => 51,
    "feedback_ids" => ["FX001", "FX002", "FX007", "FX008", "FX010", "FX011", "FX013", "FX014",
     "FX015", "FX016", "FX018", "FX019", "FX020", "FX023", "FX024", "FX026", "FX029", "FX031",
     "FX036", "FX039", "FX040", "FX041", "FX045", "FX051", "FX052", "FX053", "FX054", "FX057",
     "FX058", "FX062", "FX063", "FX064", "FX066", "FX067", "FX069", "FX071", "FX072", "FX079",
     "FX081", "FX082", "FX084", "FX085", "FX086", "FX087", "FX088", "FX089", "FX093", "FX094",
     "FX096", "FX097", "FX099"],
    "impact" => "Limiting adoption and satisfaction with AI Tools (PA002), particularly the AI Product Description Generator. Users see value in the speed and ease of use but are frustrated by inability to match their brand voice, potentially blocking Pro tier upgrades and reducing feature engagement. Arabic-speaking users face compounded frustration due to culturally inappropriate formal tone.",
    "insight_summary" => "51 users report that AI-generated content sounds robotic and overly formal, particularly in Arabic where the tone is described as too formal (\"Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹\"). Users consistently request the ability to train the AI on their brand voice and tone. While sentiment is mixed, the high volume and medium-to-high urgency signals indicate this is blocking fuller adoption of AI content generation features.",
    "insight_title" => "AI-Generated Content Lacks Brand Voice Customization and Sounds Overly Formal",
    "priority" => "high",
    "product_areas" => ["PA002", "PA007", "PA008"],
    "recommended_action" => "Prioritize development of AI Tone Trainer feature (F004) to allow users to input brand voice examples and customize output formality levels. For Arabic specifically, implement tone variation settings (formal/casual/conversational) and consider dialect-specific training data to better match regional communication styles.",
    "sentiment_distribution" => %{"mixed" => 51},
    "source_distribution" => %{"feature_feedback" => 51},
    "urgency_distribution" => %{"high" => 2, "medium" => 49}
  },
  %{
    "affected_users" => "Arabic-speaking merchants, primarily in MENA region (UAE, Saudi Arabia, and other Gulf countries), who rely on localized AI tools and proper RTL interface support for their e-commerce operations",
    "cluster_id" => "Arabic Language & Multilingual Support",
    "confidence_score" => 0.85,
    "features" => ["F003", "F012", "F004", "F011", "F001"],
    "feedback_count" => 53,
    "feedback_ids" => ["FX003", "FX004", "FX005", "FX006", "FX009", "FX017", "FX022", "FX025",
     "FX028", ...],
    ...
  },
  ...
]
```

## View Insights Summary

```elixir
if length(insights) > 0 do
  IO.puts("ğŸ¯ GENERATED INSIGHTS:\n")
  IO.puts(String.duplicate("â”", 80))
  
  insights
  |> Enum.sort_by(fn insight -> 
    priority_order = %{"critical" => 1, "high" => 2, "medium" => 3, "low" => 4}
    Map.get(priority_order, insight["priority"], 5)
  end)
  |> Enum.with_index(1)
  |> Enum.each(fn {insight, idx} ->
    priority_emoji = case insight["priority"] do
      "critical" -> "ğŸ”´"
      "high" -> "ğŸŸ "
      "medium" -> "ğŸŸ¡"
      "low" -> "ğŸŸ¢"
      _ -> "âšª"
    end
    
    IO.puts("\n#{idx}. #{priority_emoji} #{insight["insight_title"]}")
    IO.puts("   Priority: #{String.upcase(insight["priority"])} | Confidence: #{Float.round(insight["confidence_score"] * 100, 0)}%")
    IO.puts("   Evidence: #{insight["feedback_count"]} feedback items across #{map_size(insight["source_distribution"])} sources")
    IO.puts("")
    IO.puts("   ğŸ“ Summary:")
    IO.puts("   #{insight["insight_summary"]}")
    IO.puts("")
    IO.puts("   ğŸ’¥ Impact:")
    IO.puts("   #{insight["impact"]}")
    IO.puts("")
    IO.puts("   ğŸ‘¥ Affected Users:")
    IO.puts("   #{insight["affected_users"]}")
    IO.puts("")
    IO.puts("   âœ… Recommended Action:")
    IO.puts("   #{insight["recommended_action"]}")
    IO.puts("")
    IO.puts("   ğŸ“¦ Product Areas: #{Enum.join(insight["product_areas"], ", ")}")
    IO.puts("   ğŸ”§ Features: #{Enum.join(insight["features"], ", ")}")
    IO.puts(String.duplicate("â”€", 80))
  end)
  
  insights
else
  IO.puts("âš ï¸  No insights to display")
  []
end
```

<!-- livebook:{"output":true} -->

```
ğŸ¯ GENERATED INSIGHTS:

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. ğŸ”´ High Pricing Driving Significant Churn Among Small and Trial-Converting Merchants
   Priority: CRITICAL | Confidence: 88.0%
   Evidence: 59 feedback items across 3 sources

   ğŸ“ Summary:
   59 customers have churned or expressed dissatisfaction primarily due to pricing concerns, with many citing the monthly cost as unjustifiable without immediate sales results post-trial. The majority (43) came from churn surveys, indicating these concerns are directly causing customer loss. Customers are specifically requesting cheaper plans suitable for small businesses, seasonal operations, or those still validating their business model.

   ğŸ’¥ Impact:
   Causing significant customer churn with 73% of feedback coming directly from churned users. Loss of potential long-term customers who might grow into higher-tier plans. Estimated revenue loss from 43+ churned accounts, with negative word-of-mouth affecting acquisition in the small business segment.

   ğŸ‘¥ Affected Users:
   Small business owners and merchants in trial-to-paid conversion phase, seasonal businesses, and early-stage entrepreneurs who haven't achieved sales velocity to justify monthly subscription costs.

   âœ… Recommended Action:
   Introduce a lower-priced starter plan or usage-based pricing tier targeting small/seasonal merchants (e.g., transaction-based or reduced feature set at $15-20/month). Conduct pricing research with churned users to identify optimal price points and feature combinations. Implement better trial-to-paid nurturing that demonstrates ROI before payment is required.

   ğŸ“¦ Product Areas: PA004, PA006, PA001
   ğŸ”§ Features: F006, F009, F001, F002, F010
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

2. ğŸ”´ Support Response Time Issues Driving Significant Customer Churn
   Priority: CRITICAL | Confidence: 88.0%
   Evidence: 74 feedback items across 3 sources

   ğŸ“ Summary:
   74 customers reported frustration with slow support response times and support quality, with 44 customers citing this as a primary churn reason. Despite friendly interactions, the slow response times are compounding issues during critical moments like setup, payment gateway integration, and onboarding. This is particularly problematic as 44 feedbacks show high urgency, indicating customers needed immediate help but didn't receive it in time to prevent churn.

   ğŸ’¥ Impact:
   Direct driver of customer churn with 44 churned customers explicitly mentioning support issues. Lost revenue from cancelled subscriptions and negative word-of-mouth affecting acquisition. The problem spans critical customer journey moments (setup, payment integration, onboarding) where fast support could prevent early-stage abandonment.

   ğŸ‘¥ Affected Users:
   New and existing customers across all segments, particularly those in setup/onboarding phase, experiencing payment gateway integration issues, and users requiring technical assistance during trial periods before converting to paid plans.

   âœ… Recommended Action:
   Implement tiered support response SLAs with priority routing for onboarding and trial users. Expand support chat availability and team capacity to reduce response times. Create proactive support resources including live setup assistance, improved help center articles for common issues (payment gateway, setup), and automated check-ins during critical onboarding milestones.

   ğŸ“¦ Product Areas: PA006, PA001, PA004
   ğŸ”§ Features: F009, F001, F010, F006, F002
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

3. ğŸ”´ Critical Onboarding and Payment Setup Friction Driving High Churn
   Priority: CRITICAL | Confidence: 92.0%
   Evidence: 44 feedback items across 2 sources

   ğŸ“ Summary:
   44 customers report significant difficulties with initial setup and payment gateway integration, with confusing processes and inadequate support causing frustration. 75% of feedback is negative sentiment and 84% marks this as high urgency, with 86% coming directly from churn surveys indicating this is actively driving customer loss. Users specifically cite confusing payment gateway connections, lack of localized help documentation, and slow support responses during the critical onboarding phase.

   ğŸ’¥ Impact:
   Directly causing customer churn during trial-to-paid conversion, resulting in lost revenue and poor customer lifetime value. The overwhelming presence in churn surveys (38 of 44 mentions) indicates this is a primary driver of early-stage customer attrition.

   ğŸ‘¥ Affected Users:
   New merchants attempting initial store setup and payment gateway configuration, with significant impact on non-English speaking users (particularly Arabic-speaking merchants) who lack localized support resources.

   âœ… Recommended Action:
   Immediately redesign the Setup Wizard and Payment Gateway Connector with guided step-by-step flows, implement proactive in-app assistance during critical setup steps, create localized help documentation (starting with Arabic), and establish dedicated fast-track support for users in their first 7 days to reduce onboarding friction and improve trial-to-paid conversion.

   ğŸ“¦ Product Areas: PA001, PA006, PA007
   ğŸ”§ Features: F001, F002, F009, F010, F006
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

4. ğŸ”´ Platform Performance Degradation During High-Traffic Events Driving Customer Churn
   Priority: CRITICAL | Confidence: 92.0%
   Evidence: 31 feedback items across 3 sources

   ğŸ“ Summary:
   31 customers reported severe platform performance issues and system slowdowns during sales and promotional periods, with 87% marking this as high urgency. The problem is causing direct churn, with 15 customers explicitly citing technical issues and switching to competitors due to poor system performance during critical revenue-generating events. Multiple Arabic-speaking merchants mentioned speed problems during promotional periods specifically.

   ğŸ’¥ Impact:
   Directly causing customer churn to competitors during peak revenue periods (sales/promotions). Lost revenue from both churned customers and failed transactions during high-traffic events. Damaging brand reputation and merchant trust during their most critical business moments.

   ğŸ‘¥ Affected Users:
   Merchants running promotional campaigns and sales events, with notable concentration among MENA region users. Affects users across Store Management, Pricing & Plans, and Order Management functionality during peak traffic periods.

   âœ… Recommended Action:
   Immediately conduct infrastructure capacity audit and implement auto-scaling for high-traffic periods. Prioritize performance testing under promotional load scenarios. Consider implementing traffic throttling controls and pre-event capacity planning tools to prevent system degradation during known sales events.

   ğŸ“¦ Product Areas: PA003, PA007, PA004
   ğŸ”§ Features: F005, F009, F001, F006, F010
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

5. ğŸ”´ Integration Gaps and Pricing Inflexibility Driving Customer Churn
   Priority: CRITICAL | Confidence: 85.0%
   Evidence: 24 feedback items across 2 sources

   ğŸ“ Summary:
   24 customers cited insufficient third-party integrations and unsuitable pricing as primary churn reasons, with many explicitly switching to competitors like Shopify for better integration ecosystems. The platform is losing small-to-medium businesses and seasonal merchants who find the current offering either too limited in capabilities or inflexible in pricing structure. This represents a systematic competitive disadvantage in market positioning.

   ğŸ’¥ Impact:
   Direct revenue loss through customer churn, with 23 customers explicitly leaving the platform. Competitive disadvantage against Shopify and other platforms with stronger integration ecosystems. Loss of small business and seasonal merchant segments due to pricing inflexibility.

   ğŸ‘¥ Affected Users:
   Small store owners, seasonal businesses, and merchants requiring robust third-party integrations (particularly payment gateways). Predominantly customers who switched to Shopify for superior integration options.

   âœ… Recommended Action:
   Conduct competitive integration gap analysis against Shopify to prioritize top 10 missing integrations. Simultaneously introduce flexible pricing options including: pay-as-you-go plan for seasonal businesses, reduced-feature tier for small stores, and pause/resume subscription capability. Target 90-day implementation for highest-impact integrations and new pricing tiers.

   ğŸ“¦ Product Areas: PA005, PA004, PA006
   ğŸ”§ Features: F009, F006, F010, F001, F002
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

6. ğŸ”´ Lack of Centralized Feedback Management System Causing Cross-Team Inefficiencies
   Priority: CRITICAL | Confidence: 85.0%
   Evidence: 80 feedback items across 1 sources

   ğŸ“ Summary:
   80 customers have identified critical gaps in feedback management, citing scattered data across multiple tools (Google Sheets, Slack, Notion, Airtable) with no centralized repository or AI-powered analysis capabilities. Teams are currently relying on manual tagging and "team memory" to track qualitative data, making it nearly impossible to identify recurring pain points or share insights across departments. This workflow breakdown is forcing teams to use inefficient workarounds that don't scale.

   ğŸ’¥ Impact:
   Creating significant operational inefficiency with teams unable to systematically analyze customer feedback, identify trends, or collaborate on insights. This directly hampers product decision-making quality and speed, potentially leading to missed opportunities and misallocated resources. The overwhelming negative sentiment (78%) suggests this is actively frustrating users and may be causing churn.

   ğŸ‘¥ Affected Users:
   Product managers, customer success teams, UX researchers, and cross-functional stakeholders who need to collect, analyze, and act on customer feedback. Primarily affects teams conducting problem validation and those managing qualitative customer data.

   âœ… Recommended Action:
   Prioritize development of a unified feedback repository with AI-powered automatic clustering and tagging capabilities. Build a feedback dashboard (F014) that visualizes recurring themes and integrates with existing tools via APIs (PA005). Ensure cross-team collaboration features enable insight sharing and replace current manual tracking methods.

   ğŸ“¦ Product Areas: PA008, PA002, PA005
   ğŸ”§ Features: F014, F003, F013
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

7. ğŸŸ  AI-Generated Content Lacks Brand Voice Customization and Sounds Overly Formal
   Priority: HIGH | Confidence: 82.0%
   Evidence: 51 feedback items across 1 sources

   ğŸ“ Summary:
   51 users report that AI-generated content sounds robotic and overly formal, particularly in Arabic where the tone is described as too formal ("Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹"). Users consistently request the ability to train the AI on their brand voice and tone. While sentiment is mixed, the high volume and medium-to-high urgency signals indicate this is blocking fuller adoption of AI content generation features.

   ğŸ’¥ Impact:
   Limiting adoption and satisfaction with AI Tools (PA002), particularly the AI Product Description Generator. Users see value in the speed and ease of use but are frustrated by inability to match their brand voice, potentially blocking Pro tier upgrades and reducing feature engagement. Arabic-speaking users face compounded frustration due to culturally inappropriate formal tone.

   ğŸ‘¥ Affected Users:
   Merchants using AI content generation features across multiple markets, with significant impact on Arabic-speaking users in MENA region who find the formal tone culturally misaligned with their brand voice

   âœ… Recommended Action:
   Prioritize development of AI Tone Trainer feature (F004) to allow users to input brand voice examples and customize output formality levels. For Arabic specifically, implement tone variation settings (formal/casual/conversational) and consider dialect-specific training data to better match regional communication styles.

   ğŸ“¦ Product Areas: PA002, PA007, PA008
   ğŸ”§ Features: F003, F004, F014, F012, F001
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

8. ğŸŸ  Arabic Language Support Gaps Hindering MENA Market Expansion
   Priority: HIGH | Confidence: 85.0%
   Evidence: 53 feedback items across 3 sources

   ğŸ“ Summary:
   53 users report significant issues with Arabic language support across AI tools, localization, and onboarding features. Primary complaints include poor Arabic dialect handling in AI-generated content (overly formal tone), inadequate RTL theme support, and missing multilingual capabilities in core features like the AI Product Description Generator and Tone Trainer. The feedback spans multiple touchpoints (feature feedback, NPS, and user interviews), indicating a systemic localization problem rather than isolated issues.

   ğŸ’¥ Impact:
   Blocking adoption and retention among Arabic-speaking merchants in the MENA region, potentially limiting market expansion in high-growth markets like UAE and Saudi Arabia. Poor localization creates friction during onboarding and reduces the value proposition of premium AI features for this user segment.

   ğŸ‘¥ Affected Users:
   Arabic-speaking merchants, primarily in MENA region (UAE, Saudi Arabia, and other Gulf countries), who rely on localized AI tools and proper RTL interface support for their e-commerce operations

   âœ… Recommended Action:
   Prioritize a comprehensive Arabic localization sprint: 1) Enhance AI models to support Arabic dialects and adjust tone formality, 2) Complete RTL theme implementation across all features, 3) Hire native Arabic UX writer and conduct usability testing with MENA users, 4) Add Arabic language option to AI Product Description Generator and Tone Trainer as first priority

   ğŸ“¦ Product Areas: PA007, PA002, PA001
   ğŸ”§ Features: F003, F012, F004, F011, F001
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

9. ğŸŸ  Poor Feature Discoverability Blocking AI Tool Adoption
   Priority: HIGH | Confidence: 85.0%
   Evidence: 29 feedback items across 1 sources

   ğŸ“ Summary:
   29 users report difficulty finding and enabling AI tools and other features within the dashboard, with "hard to find where to enable it" being a recurring complaint. Despite users finding the AI features valuable when discovered (fast, time-saving), poor UI visibility and placement are creating friction in the user journey. This discoverability issue spans AI Product Description Generator, AI Tone Trainer, and dashboard features.

   ğŸ’¥ Impact:
   Directly blocking adoption of high-value AI features, limiting ROI on AI development investment, and potentially reducing Pro tier conversion rates. Users who can't find features won't use them, diminishing perceived product value.

   ğŸ‘¥ Affected Users:
   All dashboard users, with particular concentration among those seeking AI tools (Product Description Generator and Tone Trainer users). Affects both English and Arabic-speaking merchants across multiple product areas.

   âœ… Recommended Action:
   Conduct a UI/UX audit of feature placement and implement improved discoverability mechanisms: add prominent onboarding tooltips for AI tools, create a "New Features" or "AI Tools" section in main navigation, and consider contextual prompts that surface relevant features based on user activity. Prioritize AI tool visibility given development investment.

   ğŸ“¦ Product Areas: PA002, PA007, PA008
   ğŸ”§ Features: F003, F004, F014, F012, F005
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

10. ğŸŸ  AI Suggestion Quality Issues Despite Positive UX Feedback
   Priority: HIGH | Confidence: 82.0%
   Evidence: 42 feedback items across 1 sources

   ğŸ“ Summary:
   42 users report that while AI tools are easy to use with clear UI, the generated suggestions are frequently irrelevant or inaccurate. The issue spans multiple AI features including product description generation and tone training, with particular severity in Arabic language support. Users consistently praise usability but are frustrated by output quality, indicating a core accuracy problem rather than a UX issue.

   ğŸ’¥ Impact:
   Risk of feature abandonment and reduced perceived value of AI capabilities despite investment in usability. May prevent conversion to higher tiers that emphasize AI features, and could cause churn among Arabic-speaking merchants in high-value MENA markets.

   ğŸ‘¥ Affected Users:
   Users of AI-powered features across multiple languages, with acute issues affecting Arabic-speaking merchants. Spans users of AI Product Description Generator, AI Tone Trainer, and localization features.

   âœ… Recommended Action:
   1) Conduct immediate audit of AI model training data and relevance algorithms, particularly for Arabic language support. 2) Implement user feedback loop to collect examples of irrelevant suggestions for model retraining. 3) Add user control mechanisms allowing tone/style customization as suggested. 4) Prioritize Arabic RTL and language model improvements given specific mentions.

   ğŸ“¦ Product Areas: PA002, PA007, PA008
   ğŸ”§ Features: F003, F004, F012, F011, F013
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

11. ğŸŸ¢ AI Tools & Platform Updates Driving High User Satisfaction
   Priority: LOW | Confidence: 75.0%
   Evidence: 27 feedback items across 1 sources

   ğŸ“ Summary:
   27 NPS feedback responses show strong positive sentiment toward recent platform improvements, with particular praise for AI assistant features that save significant time. Users across Store Management, AI Tools, and Localization areas (including Arabic RTL support) are reporting improved user experience and smoother system performance after recent updates.

   ğŸ’¥ Impact:
   Reinforcing product-market fit and driving user satisfaction scores. These positive signals indicate successful feature adoption and can support customer retention, referrals, and upsell opportunities for Pro tier features.

   ğŸ‘¥ Affected Users:
   Merchants using AI Product Description Generator and AI Tone Trainer tools, including Arabic-speaking users benefiting from localization improvements (RTL themes and language switcher).

   âœ… Recommended Action:
   Capture and document these success stories as case studies for marketing materials. Identify the specific AI assistant workflows users love most through follow-up interviews to guide future AI feature development and prioritize similar time-saving enhancements.

   ğŸ“¦ Product Areas: PA003, PA002, PA007
   ğŸ”§ Features: F003, F004, F011, F012, F001
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

<!-- livebook:{"output":true} -->

```
[
  %{
    "affected_users" => "Merchants using AI content generation features across multiple markets, with significant impact on Arabic-speaking users in MENA region who find the formal tone culturally misaligned with their brand voice",
    "cluster_id" => "AI Content Quality & Tone Customization",
    "confidence_score" => 0.82,
    "features" => ["F003", "F004", "F014", "F012", "F001"],
    "feedback_count" => 51,
    "feedback_ids" => ["FX001", "FX002", "FX007", "FX008", "FX010", "FX011", "FX013", "FX014",
     "FX015", "FX016", "FX018", "FX019", "FX020", "FX023", "FX024", "FX026", "FX029", "FX031",
     "FX036", "FX039", "FX040", "FX041", "FX045", "FX051", "FX052", "FX053", "FX054", "FX057",
     "FX058", "FX062", "FX063", "FX064", "FX066", "FX067", "FX069", "FX071", "FX072", "FX079",
     "FX081", "FX082", "FX084", "FX085", "FX086", "FX087", "FX088", "FX089", "FX093", "FX094",
     "FX096", "FX097", "FX099"],
    "impact" => "Limiting adoption and satisfaction with AI Tools (PA002), particularly the AI Product Description Generator. Users see value in the speed and ease of use but are frustrated by inability to match their brand voice, potentially blocking Pro tier upgrades and reducing feature engagement. Arabic-speaking users face compounded frustration due to culturally inappropriate formal tone.",
    "insight_summary" => "51 users report that AI-generated content sounds robotic and overly formal, particularly in Arabic where the tone is described as too formal (\"Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹\"). Users consistently request the ability to train the AI on their brand voice and tone. While sentiment is mixed, the high volume and medium-to-high urgency signals indicate this is blocking fuller adoption of AI content generation features.",
    "insight_title" => "AI-Generated Content Lacks Brand Voice Customization and Sounds Overly Formal",
    "priority" => "high",
    "product_areas" => ["PA002", "PA007", "PA008"],
    "recommended_action" => "Prioritize development of AI Tone Trainer feature (F004) to allow users to input brand voice examples and customize output formality levels. For Arabic specifically, implement tone variation settings (formal/casual/conversational) and consider dialect-specific training data to better match regional communication styles.",
    "sentiment_distribution" => %{"mixed" => 51},
    "source_distribution" => %{"feature_feedback" => 51},
    "urgency_distribution" => %{"high" => 2, "medium" => 49}
  },
  %{
    "affected_users" => "Arabic-speaking merchants, primarily in MENA region (UAE, Saudi Arabia, and other Gulf countries), who rely on localized AI tools and proper RTL interface support for their e-commerce operations",
    "cluster_id" => "Arabic Language & Multilingual Support",
    "confidence_score" => 0.85,
    "features" => ["F003", "F012", "F004", "F011", "F001"],
    "feedback_count" => 53,
    "feedback_ids" => ["FX003", "FX004", "FX005", "FX006", "FX009", "FX017", "FX022", "FX025",
     "FX028", ...],
    ...
  },
  ...
]
```

## View Insights as DataFrame

```elixir
if length(insights) > 0 do
  insights_df =
    insights
    |> Enum.map(fn insight ->
      %{
        title: insight["insight_title"],
        priority: insight["priority"],
        confidence: Float.round(insight["confidence_score"], 2),
        feedback_count: insight["feedback_count"],
        sources: map_size(insight["source_distribution"]),
        impact: String.slice(insight["impact"], 0..60) <> "...",
        action: String.slice(insight["recommended_action"], 0..60) <> "..."
      }
    end)
    |> DF.new()
  
  insights_df
else
  IO.puts("âš ï¸  No insights to display")
  nil
end
```

<!-- livebook:{"output":true} -->

```text
#Explorer.DataFrame<
  Polars[11 x 7]
  action string ["Prioritize development of AI Tone Trainer feature (F004) to a...", "Prioritize a comprehensive Arabic localization sprint: 1) Enh...", "Conduct a UI/UX audit of feature placement and implement impr...", "1) Conduct immediate audit of AI model training data and rele...", "Introduce a lower-priced starter plan or usage-based pricing ...", ...]
  confidence f64 [0.82, 0.85, 0.85, 0.82, 0.88, ...]
  feedback_count s64 [51, 53, 29, 42, 59, ...]
  impact string ["Limiting adoption and satisfaction with AI Tools (PA002), par...", "Blocking adoption and retention among Arabic-speaking merchan...", "Directly blocking adoption of high-value AI features, limitin...", "Risk of feature abandonment and reduced perceived value of AI...", "Causing significant customer churn with 73% of feedback comin...", ...]
  priority string ["high", "high", "high", "high", "critical", ...]
  sources s64 [1, 3, 1, 1, 3, ...]
  title string ["AI-Generated Content Lacks Brand Voice Customization and Sounds Overly Formal", "Arabic Language Support Gaps Hindering MENA Market Expansion", "Poor Feature Discoverability Blocking AI Tool Adoption", "AI Suggestion Quality Issues Despite Positive UX Feedback", "High Pricing Driving Significant Churn Among Small and Trial-Converting Merchants", ...]
>
```

## Export Insights to JSON

```elixir
defmodule InsightExporter do
  def export_insights(insights, base_directory, filename \\ "insights_report.json") do
    path = Path.join(base_directory, filename)
    
    report = %{
      generated_at: DateTime.utc_now() |> DateTime.to_iso8601(),
      total_insights: length(insights),
      insights: insights,
      summary: %{
        by_priority: Enum.frequencies_by(insights, & &1["priority"]),
        avg_confidence: (Enum.map(insights, & &1["confidence_score"]) |> Enum.sum()) / length(insights),
        total_feedback_items: Enum.map(insights, & &1["feedback_count"]) |> Enum.sum()
      }
    }
    
    json = JSON.encode_to_iodata!(report)
    File.write!(path, json)
    
    IO.puts("âœ… Exported #{length(insights)} insights to #{filename}")
    path
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, InsightExporter, <<70, 79, 82, 49, 0, 0, 15, ...>>, ...}
```

```elixir
# Uncomment to export
# if length(insights) > 0 do
#   InsightExporter.export_insights(insights, base_directory)
# end
```

<!-- livebook:{"output":true} -->

```
nil
```

---

## Section 8: Visualizations

Create visual dashboards for insights analysis.

```elixir
# Check if we have insights to visualize
has_insights = length(insights) > 0

if has_insights do
  IO.puts("ğŸ“Š Creating visualizations for #{length(insights)} insights...")
else
  IO.puts("âš ï¸  No insights available for visualization")
end
```

<!-- livebook:{"output":true} -->

```
ğŸ“Š Creating visualizations for 11 insights...
```

<!-- livebook:{"output":true} -->

```
:ok
```

## 1. Urgency vs Sentiment Matrix (Bubble Chart)

Shows strategic positioning - which quadrant each insight falls into for decision-making.

```elixir
if has_insights do
  # Prepare data for urgency vs sentiment matrix
  matrix_data = 
    insights
    |> Enum.flat_map(fn insight ->
      # Get urgency distribution
      urgency_dist = insight["urgency_distribution"]
      total_urgency = Enum.sum(Map.values(urgency_dist))
      
      # Calculate urgency score (0-100)
      urgency_score = 
        (Map.get(urgency_dist, "high", 0) * 100 + 
         Map.get(urgency_dist, "medium", 0) * 50 + 
         Map.get(urgency_dist, "low", 0) * 0) / max(total_urgency, 1)
      
      # Get sentiment distribution
      sentiment_dist = insight["sentiment_distribution"]
      total_sentiment = Enum.sum(Map.values(sentiment_dist))
      
      # Calculate sentiment score (-100 to 100, negative is bad)
      sentiment_score = 
        (Map.get(sentiment_dist, "positive", 0) * 100 + 
         Map.get(sentiment_dist, "mixed", 0) * 0 + 
         Map.get(sentiment_dist, "neutral", 0) * 0 +
         Map.get(sentiment_dist, "negative", 0) * -100) / max(total_sentiment, 1)
      
      priority_color = case insight["priority"] do
        "critical" -> "#dc2626"
        "high" -> "#ea580c"
        "medium" -> "#fbbf24"
        "low" -> "#22c55e"
        _ -> "#94a3b8"
      end
      
      [%{
        "title" => String.slice(insight["insight_title"], 0..40) <> "...",
        "urgency_score" => Float.round(urgency_score, 1),
        "sentiment_score" => Float.round(sentiment_score, 1),
        "feedback_count" => insight["feedback_count"],
        "priority" => insight["priority"],
        "color" => priority_color,
        "confidence" => Float.round(insight["confidence_score"] * 100, 0)
      }]
    end)
  
  VegaLite.new(width: 700, height: 500, title: "Strategic Insight Matrix: Urgency vs Sentiment")
  |> VegaLite.data_from_values(matrix_data)
  |> VegaLite.mark(:circle, tooltip: true)
  |> VegaLite.encode_field(:x, "sentiment_score", 
      type: :quantitative, 
      title: "Sentiment (Negative â† â†’ Positive)",
      scale: [domain: [-100, 100]],
      axis: [grid: true]
    )
  |> VegaLite.encode_field(:y, "urgency_score", 
      type: :quantitative, 
      title: "Urgency Score (Low â† â†’ High)",
      scale: [domain: [0, 100]],
      axis: [grid: true]
    )
  |> VegaLite.encode_field(:size, "feedback_count",
      type: :quantitative,
      title: "Feedback Count",
      scale: [range: [100, 2000]]
    )
  |> VegaLite.encode_field(:color, "color",
      type: :nominal,
      scale: nil,
      legend: nil
    )
  |> VegaLite.encode(:tooltip, [
      [field: "title", type: :nominal, title: "Insight"],
      [field: "priority", type: :nominal, title: "Priority"],
      [field: "feedback_count", type: :quantitative, title: "Feedback Count"],
      [field: "confidence", type: :quantitative, title: "Confidence %"],
      [field: "urgency_score", type: :quantitative, title: "Urgency Score"],
      [field: "sentiment_score", type: :quantitative, title: "Sentiment Score"]
    ])
else
  IO.puts("âš ï¸  No insights to visualize")
  nil
end
```

<!-- livebook:{"output":true} -->

```vega-lite
{"$schema":"https://vega.github.io/schema/vega-lite/v5.json","data":{"values":[{"color":"#ea580c","confidence":82.0,"feedback_count":51,"priority":"high","sentiment_score":0.0,"title":"AI-Generated Content Lacks Brand Voice Cu...","urgency_score":52.0},{"color":"#ea580c","confidence":85.0,"feedback_count":53,"priority":"high","sentiment_score":0.0,"title":"Arabic Language Support Gaps Hindering ME...","urgency_score":50.0},{"color":"#ea580c","confidence":85.0,"feedback_count":29,"priority":"high","sentiment_score":0.0,"title":"Poor Feature Discoverability Blocking AI ...","urgency_score":46.6},{"color":"#ea580c","confidence":82.0,"feedback_count":42,"priority":"high","sentiment_score":0.0,"title":"AI Suggestion Quality Issues Despite Posi...","urgency_score":47.6},{"color":"#dc2626","confidence":88.0,"feedback_count":59,"priority":"critical","sentiment_score":-66.1,"title":"High Pricing Driving Significant Churn Am...","urgency_score":81.4},{"color":"#dc2626","confidence":88.0,"feedback_count":74,"priority":"critical","sentiment_score":6.8,"title":"Support Response Time Issues Driving Sign...","urgency_score":62.8},{"color":"#dc2626","confidence":92.0,"feedback_count":44,"priority":"critical","sentiment_score":-75.0,"title":"Critical Onboarding and Payment Setup Fri...","urgency_score":92.0},{"color":"#dc2626","confidence":92.0,"feedback_count":31,"priority":"critical","sentiment_score":-80.6,"title":"Platform Performance Degradation During H...","urgency_score":93.5},{"color":"#dc2626","confidence":85.0,"feedback_count":24,"priority":"critical","sentiment_score":-54.2,"title":"Integration Gaps and Pricing Inflexibilit...","urgency_score":87.5},{"color":"#dc2626","confidence":85.0,"feedback_count":80,"priority":"critical","sentiment_score":-97.5,"title":"Lack of Centralized Feedback Management S...","urgency_score":85.0},{"color":"#22c55e","confidence":75.0,"feedback_count":27,"priority":"low","sentiment_score":77.8,"title":"AI Tools & Platform Updates Driving High ...","urgency_score":3.7}]},"encoding":{"color":{"field":"color","legend":null,"scale":null,"type":"nominal"},"size":{"field":"feedback_count","scale":{"range":[100,2000]},"title":"Feedback Count","type":"quantitative"},"tooltip":[{"field":"title","title":"Insight","type":"nominal"},{"field":"priority","title":"Priority","type":"nominal"},{"field":"feedback_count","title":"Feedback Count","type":"quantitative"},{"field":"confidence","title":"Confidence %","type":"quantitative"},{"field":"urgency_score","title":"Urgency Score","type":"quantitative"},{"field":"sentiment_score","title":"Sentiment Score","type":"quantitative"}],"x":{"axis":{"grid":true},"field":"sentiment_score","scale":{"domain":[-100,100]},"title":"Sentiment (Negative â† â†’ Positive)","type":"quantitative"},"y":{"axis":{"grid":true},"field":"urgency_score","scale":{"domain":[0,100]},"title":"Urgency Score (Low â† â†’ High)","type":"quantitative"}},"height":500,"mark":{"tooltip":true,"type":"circle"},"title":"Strategic Insight Matrix: Urgency vs Sentiment","width":700}
```

### Matrix Interpretation Guide

```elixir
if has_insights do
  IO.puts("""
  ğŸ“ QUADRANT GUIDE:
  
  Top-Right (High Urgency + Positive Sentiment):
    â†’ Opportunity to capitalize on momentum
    â†’ Quick wins that customers are asking for
    
  Top-Left (High Urgency + Negative Sentiment):
    â†’ ğŸ”¥ EMERGENCY - Fix immediately
    â†’ Customers are frustrated AND it's urgent
    
  Bottom-Right (Low Urgency + Positive Sentiment):
    â†’ Enhancement opportunities
    â†’ Nice-to-have improvements
    
  Bottom-Left (Low Urgency + Negative Sentiment):
    â†’ Roadmap consideration
    â†’ Address when capacity allows
  
  ğŸ’¡ Bubble size = feedback volume (bigger = more mentions)
  ğŸ¨ Color = priority (red = critical, orange = high, yellow = medium, green = low)
  """)
end
```

<!-- livebook:{"output":true} -->

```
ğŸ“ QUADRANT GUIDE:

Top-Right (High Urgency + Positive Sentiment):
  â†’ Opportunity to capitalize on momentum
  â†’ Quick wins that customers are asking for
  
Top-Left (High Urgency + Negative Sentiment):
  â†’ ğŸ”¥ EMERGENCY - Fix immediately
  â†’ Customers are frustrated AND it's urgent
  
Bottom-Right (Low Urgency + Positive Sentiment):
  â†’ Enhancement opportunities
  â†’ Nice-to-have improvements
  
Bottom-Left (Low Urgency + Negative Sentiment):
  â†’ Roadmap consideration
  â†’ Address when capacity allows

ğŸ’¡ Bubble size = feedback volume (bigger = more mentions)
ğŸ¨ Color = priority (red = critical, orange = high, yellow = medium, green = low)

```

<!-- livebook:{"output":true} -->

```
:ok
```

## 2. Confidence vs Feedback Volume (Scatter Plot)

Quality assurance view - validate that high-priority insights have strong evidence.

```elixir
if has_insights do
  scatter_data = 
    insights
    |> Enum.map(fn insight ->
      priority_color = case insight["priority"] do
        "critical" -> "#dc2626"
        "high" -> "#ea580c"
        "medium" -> "#fbbf24"
        "low" -> "#22c55e"
        _ -> "#94a3b8"
      end
      
      %{
        "title" => String.slice(insight["insight_title"], 0..40) <> "...",
        "confidence" => Float.round(insight["confidence_score"] * 100, 1),
        "feedback_count" => insight["feedback_count"],
        "priority" => insight["priority"],
        "color" => priority_color,
        "sources" => map_size(insight["source_distribution"])
      }
    end)
  
  VegaLite.new(width: 700, height: 500, title: "Evidence Strength: Confidence vs Feedback Volume")
  |> VegaLite.data_from_values(scatter_data)
  |> VegaLite.mark(:point, size: 200, tooltip: true)
  |> VegaLite.encode_field(:x, "feedback_count", 
      type: :quantitative, 
      title: "Feedback Count",
      scale: [zero: true]
    )
  |> VegaLite.encode_field(:y, "confidence", 
      type: :quantitative, 
      title: "Confidence Score (%)",
      scale: [domain: [0, 100]]
    )
  |> VegaLite.encode_field(:color, "color",
      type: :nominal,
      scale: nil,
      legend: nil
    )
  |> VegaLite.encode(:tooltip, [
      [field: "title", type: :nominal, title: "Insight"],
      [field: "priority", type: :nominal, title: "Priority"],
      [field: "confidence", type: :quantitative, title: "Confidence %"],
      [field: "feedback_count", type: :quantitative, title: "Feedback Count"],
      [field: "sources", type: :quantitative, title: "Source Count"]
    ])
else
  IO.puts("âš ï¸  No insights to visualize")
  nil
end
```

<!-- livebook:{"output":true} -->

```vega-lite
{"$schema":"https://vega.github.io/schema/vega-lite/v5.json","data":{"values":[{"color":"#ea580c","confidence":82.0,"feedback_count":51,"priority":"high","sources":1,"title":"AI-Generated Content Lacks Brand Voice Cu..."},{"color":"#ea580c","confidence":85.0,"feedback_count":53,"priority":"high","sources":3,"title":"Arabic Language Support Gaps Hindering ME..."},{"color":"#ea580c","confidence":85.0,"feedback_count":29,"priority":"high","sources":1,"title":"Poor Feature Discoverability Blocking AI ..."},{"color":"#ea580c","confidence":82.0,"feedback_count":42,"priority":"high","sources":1,"title":"AI Suggestion Quality Issues Despite Posi..."},{"color":"#dc2626","confidence":88.0,"feedback_count":59,"priority":"critical","sources":3,"title":"High Pricing Driving Significant Churn Am..."},{"color":"#dc2626","confidence":88.0,"feedback_count":74,"priority":"critical","sources":3,"title":"Support Response Time Issues Driving Sign..."},{"color":"#dc2626","confidence":92.0,"feedback_count":44,"priority":"critical","sources":2,"title":"Critical Onboarding and Payment Setup Fri..."},{"color":"#dc2626","confidence":92.0,"feedback_count":31,"priority":"critical","sources":3,"title":"Platform Performance Degradation During H..."},{"color":"#dc2626","confidence":85.0,"feedback_count":24,"priority":"critical","sources":2,"title":"Integration Gaps and Pricing Inflexibilit..."},{"color":"#dc2626","confidence":85.0,"feedback_count":80,"priority":"critical","sources":1,"title":"Lack of Centralized Feedback Management S..."},{"color":"#22c55e","confidence":75.0,"feedback_count":27,"priority":"low","sources":1,"title":"AI Tools & Platform Updates Driving High ..."}]},"encoding":{"color":{"field":"color","legend":null,"scale":null,"type":"nominal"},"tooltip":[{"field":"title","title":"Insight","type":"nominal"},{"field":"priority","title":"Priority","type":"nominal"},{"field":"confidence","title":"Confidence %","type":"quantitative"},{"field":"feedback_count","title":"Feedback Count","type":"quantitative"},{"field":"sources","title":"Source Count","type":"quantitative"}],"x":{"field":"feedback_count","scale":{"zero":true},"title":"Feedback Count","type":"quantitative"},"y":{"field":"confidence","scale":{"domain":[0,100]},"title":"Confidence Score (%)","type":"quantitative"}},"height":500,"mark":{"size":200,"tooltip":true,"type":"point"},"title":"Evidence Strength: Confidence vs Feedback Volume","width":700}
```

### Confidence Analysis

```elixir
if has_insights do
  # Find outliers
  high_priority_low_confidence = 
    insights
    |> Enum.filter(fn insight ->
      insight["priority"] in ["critical", "high"] and insight["confidence_score"] < 0.6
    end)
  
  low_volume_high_confidence = 
    insights
    |> Enum.filter(fn insight ->
      insight["feedback_count"] < 5 and insight["confidence_score"] > 0.8
    end)
  
  IO.puts("ğŸ” CONFIDENCE ANALYSIS:\n")
  
  if length(high_priority_low_confidence) > 0 do
    IO.puts("âš ï¸  High Priority but Low Confidence (#{length(high_priority_low_confidence)}):")
    high_priority_low_confidence
    |> Enum.each(fn insight ->
      IO.puts("   - #{insight["insight_title"]} (#{Float.round(insight["confidence_score"] * 100, 0)}%)")
    end)
    IO.puts("   â†’ Recommendation: Validate before acting\n")
  end
  
  if length(low_volume_high_confidence) > 0 do
    IO.puts("ğŸ¤” Low Volume but High Confidence (#{length(low_volume_high_confidence)}):")
    low_volume_high_confidence
    |> Enum.each(fn insight ->
      IO.puts("   - #{insight["insight_title"]} (#{insight["feedback_count"]} items)")
    end)
    IO.puts("   â†’ Recommendation: Check if sample is representative\n")
  end
  
  if length(high_priority_low_confidence) == 0 and length(low_volume_high_confidence) == 0 do
    IO.puts("âœ… All insights have appropriate confidence levels for their priority")
  end
end
```

<!-- livebook:{"output":true} -->

```
ğŸ” CONFIDENCE ANALYSIS:

âœ… All insights have appropriate confidence levels for their priority
```

<!-- livebook:{"output":true} -->

```
:ok
```

## 3. Product Area Impact (Bar Chart)

Shows where to focus team resources based on insight concentration.

```elixir
if has_insights do
  # Get product area names
  area_lookup = Map.new(product_areas, fn area -> {area.id, area.name} end)
  
  # Aggregate insights by product area
  area_impact = 
    insights
    |> Enum.flat_map(fn insight ->
      insight["product_areas"]
      |> Enum.map(fn area_id ->
        {area_id, %{
          feedback_count: insight["feedback_count"],
          priority_score: case insight["priority"] do
            "critical" -> 4
            "high" -> 3
            "medium" -> 2
            "low" -> 1
            _ -> 0
          end
        }}
      end)
    end)
    |> Enum.group_by(fn {area_id, _} -> area_id end, fn {_, data} -> data end)
    |> Enum.map(fn {area_id, items} ->
      insight_count = length(items)
      total_feedback = Enum.sum(Enum.map(items, & &1.feedback_count))
      avg_priority = Float.round(Enum.sum(Enum.map(items, & &1.priority_score)) / insight_count, 1)
      
      %{
        "area_id" => area_id,
        "area_name" => Map.get(area_lookup, area_id, area_id),
        "insight_count" => insight_count,
        "total_feedback" => total_feedback,
        "avg_priority" => avg_priority
      }
    end)
    |> Enum.sort_by(& &1["insight_count"], :desc)
  
  VegaLite.new(width: 700, height: 400, title: "Product Area Impact (Insight Count)")
  |> VegaLite.data_from_values(area_impact)
  |> VegaLite.mark(:bar, tooltip: true, color: "#3b82f6")
  |> VegaLite.encode_field(:x, "insight_count", 
      type: :quantitative, 
      title: "Number of Insights"
    )
  |> VegaLite.encode_field(:y, "area_name", 
      type: :nominal, 
      title: "Product Area",
      sort: [field: "insight_count", order: "descending"]
    )
  |> VegaLite.encode(:tooltip, [
      [field: "area_name", type: :nominal, title: "Product Area"],
      [field: "insight_count", type: :quantitative, title: "Insights"],
      [field: "total_feedback", type: :quantitative, title: "Total Feedback Items"],
      [field: "avg_priority", type: :quantitative, title: "Avg Priority Score"]
    ])
else
  IO.puts("âš ï¸  No insights to visualize")
  nil
end
```

<!-- livebook:{"output":true} -->

```vega-lite
{"$schema":"https://vega.github.io/schema/vega-lite/v5.json","data":{"values":[{"area_id":"PA007","area_name":"Localization","avg_priority":3.0,"insight_count":7,"total_feedback":277},{"area_id":"PA002","area_name":"AI Tools","avg_priority":2.8,"insight_count":6,"total_feedback":282},{"area_id":"PA001","area_name":"Store Setup & Onboarding","avg_priority":3.8,"insight_count":4,"total_feedback":230},{"area_id":"PA004","area_name":"Pricing & Plans","avg_priority":4.0,"insight_count":4,"total_feedback":188},{"area_id":"PA006","area_name":"Customer Support","avg_priority":4.0,"insight_count":4,"total_feedback":201},{"area_id":"PA008","area_name":"Reporting & Insights","avg_priority":3.3,"insight_count":4,"total_feedback":202},{"area_id":"PA003","area_name":"Store Management","avg_priority":2.5,"insight_count":2,"total_feedback":58},{"area_id":"PA005","area_name":"Integrations & APIs","avg_priority":4.0,"insight_count":2,"total_feedback":104}]},"encoding":{"tooltip":[{"field":"area_name","title":"Product Area","type":"nominal"},{"field":"insight_count","title":"Insights","type":"quantitative"},{"field":"total_feedback","title":"Total Feedback Items","type":"quantitative"},{"field":"avg_priority","title":"Avg Priority Score","type":"quantitative"}],"x":{"field":"insight_count","title":"Number of Insights","type":"quantitative"},"y":{"field":"area_name","sort":{"field":"insight_count","order":"descending"},"title":"Product Area","type":"nominal"}},"height":400,"mark":{"color":"#3b82f6","tooltip":true,"type":"bar"},"title":"Product Area Impact (Insight Count)","width":700}
```

### Resource Allocation Recommendations

```elixir
if has_insights do
  # Get product area names
  area_lookup = Map.new(product_areas, fn area -> {area.id, area.name} end)
  
  # Calculate area concentration
  area_counts = 
    insights
    |> Enum.flat_map(& &1["product_areas"])
    |> Enum.frequencies()
  
  total_mentions = Enum.sum(Map.values(area_counts))
  
  area_percentages = 
    area_counts
    |> Enum.map(fn {area_id, count} ->
      {area_id, Float.round(count / total_mentions * 100, 1)}
    end)
    |> Enum.sort_by(fn {_, pct} -> pct end, :desc)
  
  IO.puts("ğŸ¯ RESOURCE ALLOCATION RECOMMENDATIONS:\n")
  
  area_percentages
  |> Enum.take(3)
  |> Enum.each(fn {area_id, pct} ->
    area_name = Map.get(area_lookup, area_id, area_id)
    recommendation = cond do
      pct > 40 -> "ğŸ”¥ Hot spot - dedicate squad capacity"
      pct > 25 -> "âš¡ Major focus area"
      pct > 15 -> "ğŸ“Œ Significant attention needed"
      true -> "ğŸ‘€ Monitor"
    end
    IO.puts("   #{area_name}: #{pct}% - #{recommendation}")
  end)
  
  IO.puts("\nğŸ’¡ If insights are concentrated (>40% in one area), consider dedicated team allocation")
  IO.puts("ğŸ’¡ If insights are spread evenly, consider cross-functional approach")
end
```

<!-- livebook:{"output":true} -->

```
ğŸ¯ RESOURCE ALLOCATION RECOMMENDATIONS:

   Localization: 21.2% - ğŸ“Œ Significant attention needed
   AI Tools: 18.2% - ğŸ“Œ Significant attention needed
   Store Setup & Onboarding: 12.1% - ğŸ‘€ Monitor

ğŸ’¡ If insights are concentrated (>40% in one area), consider dedicated team allocation
ğŸ’¡ If insights are spread evenly, consider cross-functional approach
```

<!-- livebook:{"output":true} -->

```
:ok
```

---

## Summary Statistics

```elixir
# Filter out errors
successful_feedback = Enum.filter(enriched_feedback, fn f -> !f.extraction_error end)

IO.puts("ğŸ“Š Successfully processed: #{length(successful_feedback)}/#{length(enriched_feedback)}\n")

# Count by source
source_counts =
  successful_feedback
  |> Enum.group_by(& &1.source)
  |> Enum.map(fn {source, items} -> {source, length(items)} end)
  |> Enum.sort_by(fn {_source, count} -> count end, :desc)

IO.puts("ğŸ“ Source Distribution:")

source_counts
|> Enum.each(fn {source, count} ->
  IO.puts("  #{source}: #{count}")
end)

# Count by sentiment
sentiment_counts =
  successful_feedback
  |> Enum.group_by(& &1.extracted_sentiment)
  |> Enum.map(fn {sentiment, items} -> {sentiment, length(items)} end)
  |> Enum.sort_by(fn {_sentiment, count} -> count end, :desc)

IO.puts("ğŸ˜Š Sentiment Distribution:")

sentiment_counts
|> Enum.each(fn {sentiment, count} ->
  IO.puts("  #{sentiment}: #{count}")
end)

# Count by urgency
urgency_counts =
  successful_feedback
  |> Enum.group_by(& &1.extracted_urgency)
  |> Enum.map(fn {urgency, items} -> {urgency, length(items)} end)
  |> Enum.sort_by(fn {_urgency, count} -> count end, :desc)

IO.puts("\nâš¡ Urgency Distribution:")

urgency_counts
|> Enum.each(fn {urgency, count} ->
  IO.puts("  #{urgency}: #{count}")
end)

# Most common product areas
product_area_counts =
  successful_feedback
  |> Enum.flat_map(& &1.extracted_product_areas)
  |> Enum.frequencies()
  |> Enum.sort_by(fn {_area, count} -> count end, :desc)

IO.puts("\nğŸ“¦ Product Area Frequency:")

product_area_counts
|> Enum.each(fn {area_id, count} ->
  area = Enum.find(product_areas, fn a -> a.id == area_id end)
  area_name = if area, do: area.name, else: "Unknown"
  IO.puts("  #{area_id} (#{area_name}): #{count} mentions")
end)

# Most common features
feature_counts =
  successful_feedback
  |> Enum.flat_map(& &1.extracted_features)
  |> Enum.frequencies()
  |> Enum.sort_by(fn {_feature, count} -> count end, :desc)
  |> Enum.take(10)

IO.puts("\nğŸ”§ Top Features Mentioned:")

feature_counts
|> Enum.each(fn {feature_id, count} ->
  feature = Enum.find(features, fn f -> f.id == feature_id end)
  feature_name = if feature, do: feature.name, else: "Unknown"
  IO.puts("  #{feature_id} (#{feature_name}): #{count} mentions")
end)
```

<!-- livebook:{"output":true} -->

```
ğŸ“Š Successfully processed: 387/387

ğŸ“ Source Distribution:
  churn_survey: 100
  feature_feedback: 100
  nps_feedback: 100
  problem_validation: 80
  user_interviews: 7
ğŸ˜Š Sentiment Distribution:
  mixed: 168
  negative: 167
  positive: 47
  neutral: 5

âš¡ Urgency Distribution:
  medium: 165
  high: 164
  low: 58

ğŸ“¦ Product Area Frequency:
  PA007 (Localization): 135 mentions
  PA002 (AI Tools): 131 mentions
  PA008 (Reporting & Insights): 96 mentions
  PA006 (Customer Support): 92 mentions
  PA004 (Pricing & Plans): 72 mentions
  PA001 (Store Setup & Onboarding): 57 mentions
  PA003 (Store Management): 53 mentions
  PA005 (Integrations & APIs): 31 mentions

ğŸ”§ Top Features Mentioned:
  F003 (AI Product Description Generator): 111 mentions
  F014 (Feedback Dashboard): 93 mentions
  F004 (AI Tone Trainer): 85 mentions
  F009 (Support Chat): 79 mentions
  F006 (Subscription Manager): 54 mentions
  F012 (Language Switcher): 50 mentions
  F001 (Setup Wizard): 44 mentions
  F010 (Help Center Articles): 31 mentions
  F011 (Arabic RTL Theme): 30 mentions
  F005 (Order Management Dashboard): 29 mentions
```

<!-- livebook:{"output":true} -->

```
:ok
```

---

## Next Steps

ğŸ‰ **Congratulations!** You now have a working POC that:

* âœ… Loads product context (areas & features)
* âœ… Loads all 5 VOC feedback sources (480+ items)
* âœ… Uses Claude Sonnet 4.5 via AWS Bedrock with structured output (generate_object)
* âœ… Agent 1: Extracts product areas, features, themes, sentiment, and urgency
* âœ… Agent 2: Clusters similar feedback into thematic groups
* âœ… Agent 3: Generates actionable insights with priority, confidence, and recommendations
* âœ… Maintains full traceability (CSV â†’ feedback â†’ clusters â†’ insights)
* âœ… Export capabilities (JSON reports with metadata)

### What's Next:

1. **Visualizations** - VegaLite charts showing:
   * Sentiment/urgency distributions across clusters
   * Source diversity heat map
2. **Advanced features**:
   * Track insights over time (detect trending issues)
   * Connect insights to OKRs and strategy
   * Generate PRDs from insights
   * Interactive dashboard for insights exploration

---
